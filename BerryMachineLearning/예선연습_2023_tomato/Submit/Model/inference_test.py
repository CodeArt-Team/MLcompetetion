"""
    ğŸ”¸ Team : ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬ íŒ€
    ğŸ”¸ Date : 2024.07.30 
    ğŸ”¸ Description: ì‚¬ì „í…ŒìŠ¤íŠ¸ ì œì¶œ íŒŒì¼ 
    ğŸ”¸ êµ¬ë™ë°©ì‹ 
        1. í™˜ê²½ë°ì´í„°ê°€ ìˆëŠ” í´ë”ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ command ì— ì…ë ¥í•©ë‹ˆë‹¤. 
        2. ìƒìœ¡ë°ì´í„°ê°€ ìˆëŠ” í´ë”ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ command ì— ì…ë ¥í•©ë‹ˆë‹¤.
        3. ëª¨ë¸ íŒŒì¼ì´ ìˆëŠ” í´ë”ì˜ ê²½ë¡œë¥¼ command ì— ì…ë ¥í•©ë‹ˆë‹¤ 
        4. outputì´  predictBerry.csv íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤. 
"""




## ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬  íŒ¨í‚¤ì§€ ì„¤ì¹˜ 
def MLLibraryInstalls():
    import subprocess
    import sys
    import warnings
    warnings.filterwarnings('ignore')
    


    def install(package):
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])
        except subprocess.CalledProcessError as e:
            print(f"Error installing {package}: {e}")
    
    # pandas ì—†ìœ¼ë©´ pandas ì„¤ì¹˜
    try:
        import pandas
    except ImportError:
        print("Installing pandas")
        install('pandas')
    finally:
        try:
            import pandas as pd
        except ImportError:
            print("Failed to import pandas after installation")

    # numpy ì—†ìœ¼ë©´ numpy ì„¤ì¹˜
    try:
        import numpy
    except ImportError:
        print("Installing numpy")
        install('numpy')
    finally:
        try:
            import numpy as np
        except ImportError:
            print("Failed to import numpy after installation")

    # sklearn ì—†ìœ¼ë©´ sklearn ì„¤ì¹˜
    try:
        import sklearn
    except ImportError:
        print("Installing sklearn")
        install('scikit-learn')
    finally:
        try:
            from sklearn.tree import DecisionTreeRegressor
            from sklearn.metrics import mean_squared_error, r2_score
        except ImportError:
            print("Failed to import sklearn modules after installation")
    # matplotlib ì—†ìœ¼ë©´ matplotlib ì„¤ì¹˜
    try:
        import matplotlib.pyplot as plt
    except ImportError:
        print("Installing sklearn")
        install('matplotlib')
    finally:
        try:
            import matplotlib.pyplot as plt
        except ImportError:
            print("Failed to import matplotlib modules after installation")
            
    # Seaborn ì—†ìœ¼ë©´ Seaborn ì„¤ì¹˜
    try:
        import seaborn
    except ImportError:
        print("Installing sklearn")
        install('seaborn')
    finally:
        try:
            import seaborn
        except ImportError:
            print("Failed to import matplotlib modules after installation")
### í•„ìš”í•œ library package install 
MLLibraryInstalls()

try:
    import pandas as pd,numpy as np ## pandas, numpy 
    import matplotlib.pyplot as plt,seaborn as sns  # ì‹œê°í™”
    import warnings; warnings.filterwarnings('ignore')  # ê²½ê³  ë¬´ì‹œ
    import sys,os # file directory access
    from pprint import pprint 
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.metrics import mean_squared_error, r2_score

    print("í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸ ì™„ë£Œ")
    import platform; print(platform.platform())
    import sys; print("Python",sys.version)
    import sklearn; print("Scikit-Learn", sklearn.__version__)
    import xgboost; print("XGBoost", xgboost.__version__)
except ImportError as e:
    print(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

# ê¸°ë³¸ ì„¸íŒ…
def colored_text(text, color='default', bold=False):
        '''
        #### ì˜ˆì‹œ ì‚¬ìš©ë²•
        print(colored_text('ì €ì¥ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.', 'red'))
        print(colored_text('ì €ì¥ í•©ë‹ˆë‹¤.', 'green'))
        default,red,green,yellow,blue, magenta, cyan, white, rest
        '''
        colors = {
            'default': '\033[99m',
            'red': '\033[91m',
            'green': '\033[92m',
            'yellow': '\033[93m',
            'blue': '\033[94m',
            'magenta': '\033[95m', #ë³´ë¼ìƒ‰
            'cyan': '\033[96m',
            'white': '\033[97m',
            'bright_black': '\033[90m',  # ë°ì€ ê²€ì •ìƒ‰ (íšŒìƒ‰)
            'bright_red': '\033[91m',  # ë°ì€ ë¹¨ê°„ìƒ‰
            'bright_green': '\033[92m',  # ë°ì€ ì´ˆë¡ìƒ‰
            'bright_yellow': '\033[93m',  # ë°ì€ ë…¸ë€ìƒ‰
            'bright_blue': '\033[94m',  # ë°ì€ íŒŒë€ìƒ‰
            'bright_magenta': '\033[95m',  # ë°ì€ ë³´ë¼ìƒ‰
            'bright_cyan': '\033[96m',  # ë°ì€ ì²­ë¡ìƒ‰
            'bright_white': '\033[97m',  # ë°ì€ í°ìƒ‰
            'reset': '\033[0m'
        }
        color_code = colors.get(color, colors['default'])
        bold_code = '\033[1m' if bold else ''
        reset_code = colors['reset']
        
        return f"{bold_code}{color_code}{text}{reset_code}"
def blue(str):return colored_text(str,'blue')
def yellow(str):return colored_text(str,'yellow')
def red(str):return colored_text(str,'red')
def green(str):return colored_text(str,'green')
import math
import time


class ReadInputOutput:
    @staticmethod
    def make_DayToWeek(dataB, dataC, dataD, dataE):
        from datetime import datetime, timedelta

        ## datetime date, time ë¶„ë¦¬
        datalist = [dataB, dataC, dataD, dataE]

        ## datetimeì„ dateë¡œ ë³€ê²½ 
        for data in datalist:
            data['datetime'] = pd.to_datetime(data['datetime'])
            data['date'] = data['datetime'].dt.date
            data['time'] = data['datetime'].dt.hour
        

        base_dateB = datetime(2023, 10, 6)
        base_dateC = datetime(2023, 9, 22)  
        base_dateD = datetime(2023, 10, 18)  
        base_dateE = datetime(2023, 9, 22)  

        base_weekB = 4
        base_weekC = 1
        base_weekD = 4
        base_weekE = 1

        # ì£¼ì°¨ ê³„ì‚° í•¨ìˆ˜
        def calculate_week(date, base_date, base_week):
            base_date_timestamp = pd.Timestamp(base_date)

            # ë‚ ì§œ ì°¨ì´ ê³„ì‚°
            delta_days = (date - base_date_timestamp).dt.days

            # ê¸°ì¤€ ì£¼ì°¨ì—ì„œ ë‚ ì§œ ì°¨ì´ë¥¼ ì£¼ ë‹¨ìœ„ë¡œ ë³€í™˜
            week = base_week + delta_days // 7
            return week


        datesB = pd.to_datetime(dataB['date']) 
        datesC = pd.to_datetime(dataC['date']) 
        datesD = pd.to_datetime(dataD['date']) 
        datesE = pd.to_datetime(dataE['date']) 

        weeksB = calculate_week(datesB, base_dateB, base_weekB)
        weeksC = calculate_week(datesC, base_dateC, base_weekC)
        weeksD = calculate_week(datesD, base_dateD, base_weekD)
        weeksE = calculate_week(datesE, base_dateE, base_weekE)

        dataB['weeks'] = weeksB
        dataC['weeks'] = weeksC
        dataD['weeks'] = weeksD
        dataE['weeks'] = weeksE

        dataB.head()

    def merge_input_output(saveFilename,input_b, input_c, input_d, input_e,output):
        from sklearn.preprocessing import MinMaxScaler
        dataB, dataC, dataD, dataE = input_b, input_c, input_d, input_e
        #ì»¬ëŸ¼ì´ë¦„ë³€ê²½
        # dataR.rename(columns={'ìƒìœ¡ì£¼ì‚¬': 'ì£¼ì°¨'}, inplace=True)

            # ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ë²— í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤
        # 'ì‹œì„¤ì•„ì´ë””' ìœ ë¬´ì— ë”°ë¥¸ row ê°¯ìˆ˜ ì˜¤ë¥˜ í™•ì¸í•˜ê¸°
        dataR = output

        pivot = pd.pivot_table(dataR, 
                                values='ì¡°ì‚¬í•­ëª©ê°’', 
                                index=['ì‹œì„¤ì•„ì´ë””','ìƒìœ¡ì£¼ì‚¬', 'ì¡°ì‚¬ì¼ì', 'í‘œë³¸ë²ˆí˜¸'], 
                                columns='ì¡°ì‚¬í•­ëª©', 
                                aggfunc='first')
        # print(pivot)
        # ì¸ë±ìŠ¤ë¥¼ ë¦¬ì…‹í•©ë‹ˆë‹¤
        pivot = pivot.reset_index()
        
        pivot = pivot.rename(columns={'ìƒìœ¡ì£¼ì‚¬': 'ì£¼ì°¨','ì°©ê³¼ìˆ˜': 'ê°œí™”ìˆ˜'})

        # pivot = pivot.drop('ì¡°ì‚¬í•­ëª©', axis=1, errors='ignore')
        print("$$$$$$")
        print(pivot.columns)
        pivot.to_csv("pivot.csv")
        # pd.read_csv()
        # print(pivot)
        pivot = pd.read_csv("pivot.csv")
        
        print(pivot)
        # pivot.head()
        from datetime import datetime, timedelta

        ## datetime date, time ë¶„ë¦¬
        datalist = [dataB, dataC, dataD, dataE]

        ## datetimeì„ dateë¡œ ë³€ê²½ 
        for data in datalist:
            data['datetime'] = pd.to_datetime(data['datetime'])
            data['date'] = data['datetime'].dt.date
            data['time'] = data['datetime'].dt.hour
        

        base_dateB = datetime(2023, 10, 6)
        base_dateC = datetime(2023, 9, 22)  
        base_dateD = datetime(2023, 10, 18)  
        base_dateE = datetime(2023, 9, 22)  

        base_weekB = 4
        base_weekC = 1
        base_weekD = 4
        base_weekE = 1

        # ì£¼ì°¨ ê³„ì‚° í•¨ìˆ˜
        def calculate_week(date, base_date, base_week):
            base_date_timestamp = pd.Timestamp(base_date)

            # ë‚ ì§œ ì°¨ì´ ê³„ì‚°
            delta_days = (date - base_date_timestamp).dt.days

            # ê¸°ì¤€ ì£¼ì°¨ì—ì„œ ë‚ ì§œ ì°¨ì´ë¥¼ ì£¼ ë‹¨ìœ„ë¡œ ë³€í™˜
            week = base_week + delta_days // 7
            return week


        datesB = pd.to_datetime(dataB['date']) 
        datesC = pd.to_datetime(dataC['date']) 
        datesD = pd.to_datetime(dataD['date']) 
        datesE = pd.to_datetime(dataE['date']) 

        weeksB = calculate_week(datesB, base_dateB, base_weekB)
        weeksC = calculate_week(datesC, base_dateC, base_weekC)
        weeksD = calculate_week(datesD, base_dateD, base_weekD)
        weeksE = calculate_week(datesE, base_dateE, base_weekE)

        dataB['weeks'] = weeksB
        dataC['weeks'] = weeksC
        dataD['weeks'] = weeksD
        dataE['weeks'] = weeksE
        

        # ì£¼ì°¨ì™€ input ë°ì´í„°ë§Œ ë°ì´í„°ì…‹ìœ¼ë¡œ ë§Œë“¬
        dataCC = dataC.iloc[: ,[2,3,4,5,6,7,10]]
        dataBB = dataB.iloc[: ,[2,3,4,5,6,7,10]]
        dataDD = dataD.iloc[: ,[2,3,4,5,6,7,10]]
        dataEE = dataE.iloc[: ,[2,3,4,5,6,7,10]]

        dataT = pd.concat([dataBB, dataCC, dataDD, dataEE], ignore_index=True)
        print(dataT)
            # ì£¼ì°¨ì™€ input ë°ì´í„°ë§Œ ë°ì´í„°ì…‹ìœ¼ë¡œ ë§Œë“¬
        dataC2 = dataC.iloc[: ,[0,2,3,4,5,6,7,10]]
        dataB2 = dataB.iloc[: ,[0,2,3,4,5,6,7,10]]
        dataD2 = dataD.iloc[: ,[0,2,3,4,5,6,7,10]]
        dataE2 = dataE.iloc[: ,[0,2,3,4,5,6,7,10]]

        # CO2 ì»¬ëŸ¼ ì •ê·œí™”
        datalist2 = [dataB2, dataC2, dataD2, dataE2]

        for data in datalist2:

            min_x = data['innerCO2'] - data['innerCO2'].min()
            min_max = data['innerCO2'].max() - data['innerCO2'].min()
            
            normalCO2 = min_x / min_max
            data['CO2'] = normalCO2
            

        dataE2
        dataT = pd.concat([dataB2, dataC2, dataD2, dataE2], ignore_index=True)

        dataT.rename(columns={"ìƒìœ¡ì£¼ì°¨":"ì£¼ì°¨"}, inplace=True)



        
        dataT.rename(columns={"ì£¼ì°¨":"weeks"}, inplace=True)
        dataT.rename(columns={"farm":"ì‹œì„¤ì•„ì´ë””"}, inplace=True)
        pivot.rename(columns={"ì£¼ì°¨":"weeks"}, inplace=True)     
        # print(dataT)
        # dataTì—ì„œ 7ì£¼ì°¨ Dë†ê°€ ë°ì´í„° ì‚­ì œ
        dataT = dataT[~((dataT['weeks'] == 7) & (dataT['ì‹œì„¤ì•„ì´ë””'] == 'Dë†ê°€'))]

        # pivotì—ì„œ 7ì£¼ì°¨ Dë†ê°€ ë°ì´í„° ì‚­ì œ
        pivot = pivot[~((pivot['weeks'] == 7) & (pivot['ì‹œì„¤ì•„ì´ë””'] == 'Dë†ê°€'))]
        pivot = pivot.iloc[:,1:]   

        dataT[dataT['ì‹œì„¤ì•„ì´ë””'] == 'Bë†ê°€'].iloc[:, 1:]

        farms = ['B', 'C', 'D', 'E']
        group_stats = {}

        for farm in farms:
            farm_data = dataT[dataT['ì‹œì„¤ì•„ì´ë””'] == f'{farm}ë†ê°€'].iloc[:, 1:]
            group_stats[farm] = farm_data.groupby('weeks').agg(['sum', 'mean', 'min', 'max', 'std','var','median'])
            
            # ì—´ ì´ë¦„ ë³€ê²½
            group_stats[farm].columns = [f'{col[0]}_{col[1]}' for col in group_stats[farm].columns]
            
            # ì¸ë±ìŠ¤ ë¦¬ì…‹ ë° ì‹œì„¤ì•„ì´ë”” ì¶”ê°€
            group_stats[farm] = group_stats[farm].reset_index()
            group_stats[farm]['ì‹œì„¤ì•„ì´ë””'] = f'{farm}ë†ê°€'

        # ëª¨ë“  ë†ê°€ì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        result = pd.concat([group_stats[farm] for farm in farms], ignore_index=True)

        # pivot ë°ì´í„°ì™€ ë³‘í•© (í•„ìš”í•œ ê²½ìš°)
        result = pd.merge(pivot, result, on=['ì‹œì„¤ì•„ì´ë””', 'weeks'], how='inner')
        # print(result.head())
        # ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
        result.to_csv(f'{saveFilename}.csv', index=False)
    @staticmethod
    def model_apply():
        
        import joblib

        

        print("ddd")
        print(green("3.ëª¨ë¸ì´ ì €ì¥ëœ í´ë”ì˜ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:\n"))
        model_path  = str(sys.stdin.readline().rstrip())
        model =joblib.load(os.path.join(model_path,"rfRegressor_berry.h5"))

        import h5py
        

        
        model = joblib.load(os.path.join(model_path, "rfRegressor_berry.h5"))

        # # ëª¨ë¸ê³¼ ì…ë ¥ ì»¬ëŸ¼ ì´ë¦„ ë¶ˆëŸ¬ì˜¤ê¸°
        # h5_filename = 'rfRegressor_berry.h5'
        # with h5py.File(h5_filename, 'r') as h5file:
        #     # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
        #     rf_data = h5file['model'][()]
        #     loaded_rf = joblib.loads(rf_data.tobytes())
            
        #     # ì…ë ¥ ì»¬ëŸ¼ ì´ë¦„ ë¶ˆëŸ¬ì˜¤ê¸°
        #     input_columns = h5file['input_columns'][()].tolist()

        # # ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ê³¼ ì…ë ¥ ì»¬ëŸ¼ ì´ë¦„ í™•ì¸
        # print("Input Columns:", input_columns)
        # print("Loaded Model:", loaded_rf)


        

        # print("input columns : ",input_columns)
        data = pd.read_csv("ML_final.csv")



        x = data[['weeks', 'í‘œë³¸ë²ˆí˜¸', 'supplyEC_sum', 'supplyEC_mean',
       'supplyEC_min', 'supplyEC_max', 'supplyEC_std', 'supplyEC_var',
       'supplyEC_median', 'supplyPH_sum', 'supplyPH_mean', 'supplyPH_min',
       'supplyPH_max', 'supplyPH_std', 'supplyPH_var', 'supplyPH_median',
       'innerCO2_sum', 'innerCO2_mean', 'innerCO2_min', 'innerCO2_max',
       'innerCO2_std', 'innerCO2_var', 'innerCO2_median', 'innerHum_sum',
       'innerHum_mean', 'innerHum_min', 'innerHum_max', 'innerHum_std',
       'innerHum_var', 'innerHum_median', 'innerTemp_sum', 'innerTemp_mean',
       'innerTemp_min', 'innerTemp_max', 'innerTemp_std', 'innerTemp_var',
       'innerTemp_median', 'innerSolar_sum', 'innerSolar_mean',
       'innerSolar_min', 'innerSolar_max', 'innerSolar_std', 'innerSolar_var',
       'innerSolar_median']]
        
        pred = model.predict(x)
        df = pd.DataFrame(pred)
        df.columns = ['ê´€ë¶€ì§ê²½','ì—½ë³‘ì¥','ì—½ìˆ˜','ì—½ì¥','ì—½í­','ê°œí™”ìˆ˜','ì´ˆì¥','í™”ë°© ê½ƒìˆ˜(ì†Œí™”ìˆ˜)']
        df.to_csv("predictBerry.csv",index=None)


        



        





        
    
    
    @staticmethod
    def main():
        print("\n")
        print(green("1.í™˜ê²½ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” í´ë”ì˜ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” :\n"))
        input_env_data_folder_path  = str(sys.stdin.readline().rstrip())
        print(" input env data folder path : ",input_env_data_folder_path)
        if os.path.isdir(input_env_data_folder_path):
            for file in os.listdir(input_env_data_folder_path):
                # print(file)
                if file == "environmentsB.csv":
                    input_b=pd.read_csv(os.path.join(input_env_data_folder_path,file))
                    print("input b ì…ë ¥ ì™„ë£Œ")
                if file == "environmentsC.csv":
                    input_c=pd.read_csv(os.path.join(input_env_data_folder_path,file))
                    print("input c ì…ë ¥ ì™„ë£Œ")
                if file == "environmentsD.csv":
                    input_d=pd.read_csv(os.path.join(input_env_data_folder_path,file))
                    print("input d ì…ë ¥ ì™„ë£Œ")
                if file == "environmentsE.csv":
                    input_e=pd.read_csv(os.path.join(input_env_data_folder_path,file))
                    print("input e ì…ë ¥ ì™„ë£Œ")  
            else: print(" ëª¨ë“  ë°ì´í„°ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤")
        else : print("ê²½ë¡œë¥¼ ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš” ")
        print(green("2.ìƒìœ¡ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” í´ë”ì˜ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” :\n"))
        output_growth_data_folder_path  = str(sys.stdin.readline().rstrip())

        
        output=pd.read_excel(os.path.join(output_growth_data_folder_path,"ì‚¬ì „í…ŒìŠ¤íŠ¸-ìƒìœ¡ë°ì´í„°.xlsx"))


        
        ### output data Fetching 
        print(yellow("ğŸ”¹ Data preprocessing Start--->"))
        ReadInputOutput.merge_input_output("ML_final",input_b, input_c, input_d, input_e,output)
        ReadInputOutput.model_apply()



# print(output.tail())
# print(input_b.tail())

# /Users/ji-hwanpark/Desktop/ê³µëª¨ì „/git/BerryMLcompetetion/BerryMachineLearning/Data/ì‚¬ì „í…ŒìŠ¤íŠ¸-í™˜ê²½ë°ì´í„°
# /Users/ji-hwanpark/Desktop/ê³µëª¨ì „/git/BerryMLcompetetion/BerryMachineLearning/Data/ìƒìœ¡ë°ì´í„°
# /Users/ji-hwanpark/Desktop/ê³µëª¨ì „/git/BerryMLcompetetion/BerryMachineLearning/











if __name__ == "__main__":
    ReadInputOutput.main()