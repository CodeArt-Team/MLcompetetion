''' 
ğŸ“Œ Description :  

    - ê²½ì§„ëŒ€íšŒ ë°ì´í„° ì…‹ ë³´ê¸°ìœ„í•œ í•¨ìˆ˜ë“¤ ...
    - Visualization Class :
        0)
    - DataPreprocessing class :
        0) plotSetting
        1) DataInfo
        2) column_hist
        3) column_zero_find
        4) show_corr
    - ModelTest class 
        1) real_pred_compare
        2) linear_regressor_prdict
        3) knn_regressor_predict
        4) xgboost_regressor_predict
        5) randomforest_regressor_predict
ğŸ“Œ Date : 2024.06.02 
ğŸ“Œ Author : Forrest D Park 
ğŸ“Œ Update : 
    2024.08.07 by pdg : DataInfo í•¨ìˆ˜ ìƒì„±

'''

def imd(image_address,width =700, height=300):
    print(f'<br><img src = "{image_address}" width="{width}" height="{height}"/><br>')

def colored_text(text, color='default', bold=False):
        '''
        #### ì˜ˆì‹œ ì‚¬ìš©ë²•
        print(colored_text('ì €ì¥ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.', 'red'))
        print(colored_text('ì €ì¥ í•©ë‹ˆë‹¤.', 'green'))
        default,red,green,yellow,blue, magenta, cyan, white, rest
        '''
        colors = {
            'default': '\033[99m',
            'red': '\033[91m',
            'green': '\033[92m',
            'yellow': '\033[93m',
            'blue': '\033[94m',
            'magenta': '\033[95m', #ë³´ë¼ìƒ‰
            'cyan': '\033[96m',
            'white': '\033[97m',
            'bright_black': '\033[90m',  # ë°ì€ ê²€ì •ìƒ‰ (íšŒìƒ‰)
            'bright_red': '\033[91m',  # ë°ì€ ë¹¨ê°„ìƒ‰
            'bright_green': '\033[92m',  # ë°ì€ ì´ˆë¡ìƒ‰
            'bright_yellow': '\033[93m',  # ë°ì€ ë…¸ë€ìƒ‰
            'bright_blue': '\033[94m',  # ë°ì€ íŒŒë€ìƒ‰
            'bright_magenta': '\033[95m',  # ë°ì€ ë³´ë¼ìƒ‰
            'bright_cyan': '\033[96m',  # ë°ì€ ì²­ë¡ìƒ‰
            'bright_white': '\033[97m',  # ë°ì€ í°ìƒ‰
            'reset': '\033[0m'
        }
        color_code = colors.get(color, colors['default'])
        bold_code = '\033[1m' if bold else ''
        reset_code = colors['reset']
        
        return f"{bold_code}{color_code}{text}{reset_code}"
def blue(str,b=False):return colored_text(str,'blue',bold=b)
def yellow(str,b=False):return colored_text(str,'yellow',bold=b)
def red(str,b=False):return colored_text(str,'red',bold=b)
def green(str,b=False):return colored_text(str,'green',bold=b)
def magenta(str,b=False):return colored_text(str,'magenta',bold=b)
def Explaination(title,explain):
    title =str(title).upper()
    print(colored_text(f"___ ğŸŸ¡ {title}. ",'green',bold=True))
    print(colored_text(f"______ ğŸ“Œ {explain}",'yellow'))


### Common  library install 
# !pip install numpy
# !pip install matplotlib
# !pip install pandas


class DataAcquisition():
    def selenium_APIdata_get(endpoint_base,encode_key,pageNum=1,Rows=1):
        from urllib.parse import urlencode,unquote
        decode_key ="w1N+WdpiUt4yMy2JifOenamzNXc6HCceZ596C21rNM+LICP2KiUHN0E0F3Zf4Yu13zM8Myc/ZtIzgFBcywyxXQ=="
        queryString ="?"+urlencode(
            {
                "serviceKey":unquote(f"{encode_key}"),
                "pageNo":1,
                "numOfRows":1,
                "resultType":"json",
                
            }
        )
        query_URL = endpoint_base+queryString
        # !pip install selenium
        # !pip install webdriver-manager
        from selenium import webdriver
        from selenium.webdriver.chrome.service import Service
        from webdriver_manager.chrome import ChromeDriverManager
        from selenium.webdriver.common.by import By
        import json
        from pprint import pprint
        # Chrome browser  ì™€ Chrome Driver Version í™•ì¸í•˜ê¸° 
        chrome_options = webdriver.ChromeOptions()

        hrome_options = webdriver.ChromeOptions()
        chrome_options.add_argument('--headless')  # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ í™œì„±í™”
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
        driver.get(query_URL)
        data =driver.find_element(By.XPATH,'/html/body/pre').text
        data_json = json.loads(data)

        pprint(data_json["response"])
    
    def request_APIData_get():
        ## Author : ì§€í™˜ íŒ
        import requests
        import logging
        import ssl
        import pandas as pd
        from requests.adapters import HTTPAdapter
        from requests.packages.urllib3.util.ssl_ import create_urllib3_context

        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

        # SSL ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        ctx = create_urllib3_context()
        ctx.set_ciphers('DEFAULT@SECLEVEL=1')

        # ì»¤ìŠ¤í…€ ì–´ëŒ‘í„° í´ë˜ìŠ¤ ì •ì˜
        class CustomAdapter(HTTPAdapter):
            def init_poolmanager(self, *args, **kwargs):
                kwargs['ssl_context'] = ctx
                return super(CustomAdapter, self).init_poolmanager(*args, **kwargs)

        # ì„¸ì…˜ ìƒì„± ë° ì–´ëŒ‘í„° ì„¤ì •
        session = requests.Session()
        session.mount('https://', CustomAdapter())

        # API ì—”ë“œí¬ì¸íŠ¸ URL
        url = "https://apis.data.go.kr/B190001/cardFranchisesV3/cardV3"

        # ì¸ì¦í‚¤
        api_key = "1gpaK4ticgtOqnE5t7cIOQtKz7kP4Lu3HbyACKUWni5Ag/yj9cl9uueNXK20lnGIEqPnYSMiSOmR61YL9xS40g=="

        # ìš”ì²­ íŒŒë¼ë¯¸í„°
        params = {
            "serviceKey": api_key,
            "page": "1",
            "perPage": "3000"
        }

        # ìš”ì²­ í—¤ë”
        headers = {
            "accept": "*/*",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
        }

        try:
            # GET ìš”ì²­ ë³´ë‚´ê¸°
            response = session.get(url, params=params, headers=headers, timeout=30)
            
            # ì‘ë‹µ ìƒíƒœ í™•ì¸
            response.raise_for_status()
            
            # JSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„° íŒŒì‹±
            data = response.json()
            
            # ë°ì´í„° ì¶”ì¶œ ë° DataFrame ìƒì„±
            items = data.get('data', [])
            if items:
                df = pd.DataFrame(items)
                logging.info("DataFrame ìƒì„± ì™„ë£Œ")
                logging.info(f"DataFrame shape: {df.shape}")
                logging.info("\nDataFrame ì²« 5í–‰:")
                logging.info(df.head().to_string())
            else:
                logging.warning("ì¶”ì¶œëœ ë°ì´í„° í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                logging.info("ì‘ë‹µ ë°ì´í„°:")
                logging.info(json.dumps(data, indent=2, ensure_ascii=False))

        except requests.exceptions.RequestException as e:
            logging.error(f"ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            if hasattr(e, 'response') and e.response is not None:
                logging.error(f"ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {e.response.status_code}")
                logging.error(f"ì‘ë‹µ ë‚´ìš©: {e.response.text}")
            else:
                logging.error("ì‘ë‹µ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except ValueError as e:
            logging.error(f"JSON ë””ì½”ë”© ì˜¤ë¥˜: {e}")
            logging.error(f"ì‘ë‹µ ë‚´ìš©: {response.text}")
        except Exception as e:
            logging.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

class Visualization():
    
    def plot_boxplots(datasets, titles, figsize=(10, 20)):
        
        import seaborn as sns
        import matplotlib.pyplot as plt
        import platform,os
        from matplotlib import font_manager, rc
        

        # ì‹œê°í™” ì„¤ì •
        plt.style.use("seaborn-v0_8")
        plt.rcParams['axes.unicode_minus'] = False
        
        # ì‹œìŠ¤í…œì— ë”°ë¥¸ í°íŠ¸ ì„¤ì •
        if platform.system() == 'Darwin': 
            rc('font', family='AppleGothic')
        elif platform.system() == 'Windows': 
            path = 'c:/Windows/Fonts/malgun.ttf' 
            font_name = font_manager.FontProperties(fname=path).get_name()
            rc('font', family=font_name)
        else:
            print("Unknown System")

        # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        fig, axes = plt.subplots(len(datasets), 1, figsize=figsize)  # ë°ì´í„°ì…‹ ê°œìˆ˜ì— ë”°ë¼ ì„œë¸Œí”Œë¡¯ ìƒì„±

        for i, data in enumerate(datasets):
            sns.boxplot(data=data, ax=axes[i])
            axes[i].set_title(titles[i])

        # ê·¸ë˜í”„ ê°„ê²© ì¡°ì ˆ
        plt.tight_layout()

        # ê·¸ë˜í”„ ì¶œë ¥
        plt.show()
        # í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì‹œ
        # datasets = [out, B, C, D, E]
        # titles = ['ì‚¬ì „í…ŒìŠ¤íŠ¸ ìƒìœ¡ë°ì´í„°', 'í™˜ê²½ ë°ì´í„° B', 'í™˜ê²½ ë°ì´í„° C', 'í™˜ê²½ ë°ì´í„° D', 'í™˜ê²½ ë°ì´í„° E']
        # plot_boxplots(datasets, titles)

class DataPreprocessing:
    def __init__(self) -> None:
        pass
    def data_fetch(data_folder_path):
        import os,pandas as pd
        from tqdm import tqdm  # ì§„í–‰ ìƒí™© í‘œì‹œ ë¼ì´ë¸ŒëŸ¬ë¦¬
        data_dict ={}
        for i in tqdm(os.listdir("./ë°ì´í„°íŒŒì¼")):

            if int(i.split(".")[0]) in range(21,29):
               
                # print(int(i.split(".")[0]))
                data_dict[f"{i}"]= pd.read_excel(os.path.join("./ë°ì´í„°íŒŒì¼", i))
                
        else : 
            for i in sorted(data_dict.keys()):print(yellow(f"  {i}"))
        return data_dict
    
    def plotSetting(pltStyle="seaborn-v0_8", Title = ""):
        '''
        # Fucntion Description : Plot í•œê¸€í™” Setting
        # Date : 2024.06.05
        # Author : Forrest D Park 
        # update : 
        '''

        
        import warnings ;warnings.filterwarnings('ignore')
        import sys ;sys.path.append("../../../")
        import os 
        print(blue(f"â— í˜„ì¬ ê²½ë¡œì˜ íŒŒì¼ë“¤ ëª©ë¡ --",True))
        for i,file in enumerate(os.listdir(os.getcwd())):
            print(yellow(f"  {i}. {file}"))
        sys.path.append("../")
        sys.path.append("../../")
        random_imoticon = ["ğŸ™€","ğŸ‘»","ğŸ˜œ","ğŸ¤—","ğŸ™„","ğŸ¤‘","ğŸ¤–"]
        import numpy as np
        import random
        
        print(blue(f"â— ì£¼í”¼í„° ê°€ìƒí™˜ê²½ ì²´í¬ : {os.environ['CONDA_DEFAULT_ENV']}",True))
        print(blue(f"â— Python ì„¤ì¹˜ ê²½ë¡œ:{sys.executable}",True))

        print(blue(f"â— Graph í•œê¸€í™” Setting",True))
        
        imo = random_imoticon[random.randrange(1,len(random_imoticon))]
        # graph style seaborn
        import matplotlib.pyplot as plt # visiulization
        import platform
        from matplotlib import font_manager, rc # rc : í°íŠ¸ ë³€ê²½ ëª¨ë“ˆfont_manager : í°íŠ¸ ê´€ë¦¬ ëª¨ë“ˆ
        plt.style.use(pltStyle)
        plt.rcParams['axes.unicode_minus'] = False# unicode ì„¤ì •
        if platform.system() == 'Darwin': rc('font', family='AppleGothic') # osê°€ macos
        elif platform.system() == 'Windows': # osê°€ windows
            path = 'c:/Windows/Fonts/malgun.ttf' 
            font_name = font_manager.FontProperties(fname=path).get_name()
            rc('font', family=font_name)
        else:
            print("Unknown System")
        print(colored_text("______ğŸ‘ğŸ‘ OS platform í•œê¸€ ì„¸íŒ…ì™„ë£Œ",'magenta',bold=True))
        print(yellow(f"âœ»âœ»âœ»âœ»______{imo*1} {Title} {imo*1}______âœ»âœ»âœ»âœ»",True))

    def dataInfo(df, replace_Nan=False, PrintOutColnumber = 0,nanFillValue=0, graphPlot=True):
        column_count = len(df.columns)
        row_count = len(df.index)
        nul_count  = df.isnull().sum().sum()
        value_kind_limit =10
        under_limit_columns =[]
        if PrintOutColnumber ==0 :
            PrintOutColnumber = column_count
        print(yellow(f"- column ìˆ˜ : {column_count}"))
        print(df.columns)
        print(yellow(f"- row ìˆ˜    : {row_count}"))
        print(yellow(f"- null ìˆ˜   : {nul_count}"))
        
        
        for idx, col in enumerate(df.columns):
            if df[f"{col}"].isnull().sum():
                print(f"   => {idx}ë²ˆì§¸.[{col}]ì»¬ëŸ¼ : ",f"null {df[f'{col}'].isnull().sum()} ê°œ,\t not null {df[f'{col}'].notnull().sum()} ê°œ")
                ## Null data fill
                if replace_Nan : ## nan ì„ 0 ìœ¼ë¡œ ëŒ€ì²´ 
                    df=df[col].fillna(value=nanFillValue, inplace=True)  
        print(yellow("- ì¹¼ëŸ¼ë³„ ë°ì´í„° ì¤‘ë³µì²´í¬"))
        print( yellow("idx.columName |\t\t\t\t |Colum Info(dtype)|** "))
        print( "",yellow("--"*len("columIdx |\t\t\t\t **|Col(dtype)|** ")))
        for idx, col in enumerate(df.dtypes.keys()):
            if idx < PrintOutColnumber: ### -> ì¶œë ¥í•  ì¹¼ëŸ¼ìˆ˜ ì œí•œ 
                if len(f"\t{idx}.[{col}({df.dtypes[col]})]:")<25 : ### ì´ì˜ê²Œ ì¶œë ¥í•˜ê¸° ìœ„í•´ ì¹¼ëŸ¼ ì´ë¦„ ê¸€ììˆ˜ 25ê°œ ì´í•˜ ì¸ê²ƒì€ íƒ­ì„ ë‘ë²ˆë§Œ í•¨. 
                    value_counts = df[col].value_counts()
                    if len(df[col].unique())<10: #ì¤‘ë³µê°’ì´ 10 ì´í•˜ì¼ê²½ìš° value count ì¶œë ¥
                        under_limit_columns.append(col)
                        print(yellow(f"{idx}.[{col}({df.dtypes[col]})]:\t\t"),\
                            red(f"{len(df[col].unique())}"),\
                            green(f"\t/{len(df[col])} ")+ "\t[uniq/raw]",\
                            blue(f"---ğŸ“Œê°’ì˜ ì¢…ë¥˜ê°€ {value_kind_limit}ê°œ ë¯¸ë§Œ ì…ë‹ˆë‹¤. "),\
                             sep=" ")
                        ### Value count ê°’ ë¶„í¬ í™•ì¸
                        print("\t\t",magenta("--"*20))
                        for order,(i,v) in enumerate(zip(value_counts.index.tolist(), value_counts.values.tolist())):
                            print(magenta(f"\t\t |-[{order}] {i} : \t{v}"))
                        print("\t\t",magenta("--"*20))
                        if graphPlot :DataPreprocessing.column_hist(df,col)

                    else: 
                        print(yellow(f"{idx}.[{col}({df.dtypes[col]})]:\t\t"),\
                        red(f"{len(df[col].unique())}"),f"\t/{len(df[col])} \t[uniq/raw]",\
                             sep=" ")
                        if graphPlot :DataPreprocessing.column_hist(df,col)

                        
                    
                else:### ì´ì˜ê²Œ ì¶œë ¥í•˜ê¸° ìœ„í•´ ì¹¼ëŸ¼ ì´ë¦„ ê¸€ììˆ˜ 25ê°œ ì´ìƒ ì¸ê²ƒì€ íƒ­ì„ ë‘ë²ˆë§Œ í•¨. 
                    
                    value_counts = df[col].value_counts()
                    if len(df[col].unique())<10: #ì¤‘ë³µê°’ì´ 10 ì´í•˜ì¼ê²½ìš° value count ì¶œë ¥
                        under_limit_columns.append(col)
                        print(yellow(f"{idx}.[{col}({df.dtypes[col]})]:\t\t"),\
                        red(f"{len(df[col].unique())}"),\
                        green(f"\t/{len(df[col])} ")+ "\t[uniq/raw]",\
                            blue(f"---ğŸ“Œê°’ì˜ ì¢…ë¥˜ê°€ {value_kind_limit}ê°œ ë¯¸ë§Œ ì…ë‹ˆë‹¤. "),\
                             sep=" ")
                        print("\t\t",magenta("--"*20))
                        for order,(i,v) in enumerate(zip(value_counts.index.tolist(), value_counts.values.tolist())):
                            print(magenta(f"\t\t |-[{order}] {i} : \t{v}"))
                        print("\t\t",magenta("--"*20))
                        if graphPlot :DataPreprocessing.column_hist(df,col)


        else: 
            print(f"\t ...etc (ì¶”ê°€ë¡œ {len(df.dtypes.keys())-PrintOutColnumber}ê°œì˜ ì¹¼ëŸ¼ì´ ìˆìŠµë‹ˆë‹¤ )")
            print(red("\t[RESULT]"),"ğŸ™€ğŸ™€ğŸ™€"*10)
            print(yellow(f"\tğŸŸ¦{value_kind_limit}ê°œì´í•˜ì˜ ê°’ ì¢…ë¥˜ë¥¼ ê°€ì§€ëŠ” ì¹¼ëŸ¼ "))
            # print(red(str(under_limit_columns)))
            for col in under_limit_columns:
                print("\t\t-",yellow(f"{col}:{len(df[col].unique())}: {df[col].unique().tolist()}"))
            else:
                
                print("\t",red(f"ì´ {len(under_limit_columns)}ê°œ"))
                return under_limit_columns
        
    def column_hist(df,col):
        import pandas as pd
        import matplotlib.pyplot as plt
        import seaborn as sns
        import numpy as np
        num_cols = df.select_dtypes(include=np.number).columns  # ìˆ«ìí˜• ì¹¼ëŸ¼ë§Œ ì„ íƒ

        if col in num_cols:
            plt.figure(figsize=(5, 4))
            # íˆìŠ¤í† ê·¸ë¨ê³¼ KDE ë™ì‹œì— ê·¸ë¦¬ê¸°
            sns.histplot(df[col], kde=True, bins=30)
            plt.title(f"{col} -Histogram", fontsize=15)
            plt.xlabel(col, fontsize=12)
            plt.ylabel("Density", fontsize=12)
             # ê¸°ìˆ  í†µê³„ì¹˜ ê³„ì‚°
            mean_val = df[col].mean()
            median_val = df[col].median()
            std_val = df[col].std()
            min_val = df[col].min()
            max_val = df[col].max()

            # ê·¸ë˜í”„ì— ê¸°ìˆ  í†µê³„ì¹˜ ì¶”ê°€
            stats_text = (
            
            f"""í‰ê· ê°’ : {mean_val:<10.1f}
            ì¤‘ì•™ê°’ : {median_val:<10.1f}
            í‘œì¤€í¸ì°¨: {std_val:<10.1f}
            ìµœì†Œê°’ : {min_val:<10.1f}
            ìµœëŒ€ê°’ : {max_val:<10.1f}"""
            )
            
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì¡°ì • (ì¢Œí•˜ë‹¨)
            plt.text(x=0.95, y=0.95, s=stats_text, fontsize=8, 
                    ha='right', va='top', transform=plt.gca().transAxes, 
                    bbox=dict(facecolor='white', alpha=0.7))
            plt.show()
        else: 
            print(colored_text("ìˆ«ìí˜•ë°ì´í„°ê°€ ì•„ë‹™ë‹ˆë‹¤",'red',bold=True))
            # sns.histplot(df[col], kde=True, bins=len(df[col].unique()))
            # plt.xticks(rotation=45)  # xì¶• ë¼ë²¨ì„ 45ë„ ê¸°ìš¸ì…ë‹ˆë‹¤
            # plt.show()

    # ê° ì»¬ëŸ¼ë³„ 0 ê°’ ë¹„ìœ¨,ê°¯ìˆ˜ë³´ê¸°
    def column_zero_find(data):
        import matplotlib.pyplot as plt
        dataCount = data.columns.shape[0]
        for i in range(dataCount):

            data.columns[i]
            count_zero = (data[data.columns[i]] == 0).sum()
            count_non_zero = (data[data.columns[i]] != 0).sum()
            sizes = [count_zero, count_non_zero]
            labels = [f'{count_zero}ê°œ\n0ì¸ ë°ì´í„°', f'{count_non_zero}ê°œ\n0ì´ ì•„ë‹Œ ë°ì´í„°']
            colors = ['#ff9999','#66b3ff']
            
            #íŒŒì´ì°¨íŠ¸ ìƒì„±
            plt.figure(figsize=(3, 3))
            plt.title(f"{data.columns[i]}ì»¬ëŸ¼ 0ë¹„ìœ¨")
            plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)
            plt.axis('equal')
            plt.show()

    # ê° ì»¬ëŸ¼ë³„ ìƒê´€ë„ ë†’ì€ìˆœìœ¼ë¡œ ë½‘ê¸°
    def show_corr(data,count):
        import numpy as np
        data2 = data.select_dtypes(include=np.number).columns
        filtered_corr = data2.corr()
        for i in range(len(filtered_corr.columns)):
            abs_values = filtered_corr[filtered_corr.columns[i]].abs()

            top_values = abs_values.nlargest(count)
            print(f"{filtered_corr.columns[i]} ì»¬ëŸ¼ì˜ ìƒê´€ê³„ìˆ˜ íƒ‘ 5\n\n",top_values[0:count],"\n")
    
    
        ## ë†ê°€ë³„ë¡œ ë°ì´í„° ë‚˜ëˆ„ê¸° 
    def seperate_col_data(df,colname):
        # df  =out
        # colname ='ì‹œì„¤ì•„ì´ë””'
        uniq_of_col_data = df[colname].unique().tolist()
        print(yellow(f" {colname}ì—ëŠ” {len(uniq_of_col_data)} ì¢…ë¥˜ì˜ ë°ì´í„° ê°€ìˆìŠµë‹ˆë‹¤. "))
        seperated_data = {}
        for i in uniq_of_col_data:
            seperated_data[i] = df[df[colname]==i] 
        data_shapes=[seperated_data[i].shape for i in uniq_of_col_data]
        
        print(yellow(f" ê¸°ì¡´ì˜ data ë¥¼ "))
        for (i,j) in zip(list(seperated_data.keys()),data_shapes):
            print(yellow(f"  {i} : {j}"))
        else:print(yellow(f" ë¡œ ìª¼ê°­ë‹ˆë‹¤"))
        
        # print(yellow(f"{}"))
        # return seperated_data
    ## ë†ì‚¬ê¸°ê°„ ê³„ì‚°
    def calc_duration(df, datetime_col):
        from datetime import datetime
        if datetime_col in df.columns :
            if df[datetime_col].dtype=='O':
                test_dt_start= df[datetime_col].sort_values(ignore_index=True,ascending=True).tolist()[0]
                test_dt_end= df[datetime_col].sort_values(ignore_index=True,ascending=True).tolist()[-1]
                
                # datetime.fromtimestamp(test_dt)
                date_start = datetime.strptime(test_dt_start, '%Y-%m-%d %H:%M').date()
                date_end = datetime.strptime(test_dt_end, '%Y-%m-%d %H:%M').date()
                return (date_end- date_start).days
            elif df[datetime_col].dtype=='int64':
                test_dt_start= df[datetime_col].sort_values(ignore_index=True,ascending=True).tolist()[0]
                test_dt_end= df[datetime_col].sort_values(ignore_index=True,ascending=True).tolist()[-1]
                date_start = datetime.strptime(str(test_dt_start), '%Y%m%d')
                date_end = datetime.strptime(str(test_dt_end), '%Y%m%d')
                return (date_end- date_start).days
    ## ì£¼ì°¨ ê³„ì‚° í•¨ìˆ˜
    def calculate_week(date, base_date, base_week):
            base_date_timestamp = pd.Timestamp(base_date)

            # ë‚ ì§œ ì°¨ì´ ê³„ì‚°
            delta_days = (date - base_date_timestamp).dt.days

            # ê¸°ì¤€ ì£¼ì°¨ì—ì„œ ë‚ ì§œ ì°¨ì´ë¥¼ ì£¼ ë‹¨ìœ„ë¡œ ë³€í™˜
            week = base_week + delta_days // 7
            return week
    
class ModelTest():
    # ì˜ˆì‹œ ë°ì´í„° (training_tableê³¼ target_tableì´ ì´ë¯¸ ì¡´ì¬í•œë‹¤ê³  ê°€ì •)
    # training_table = pd.DataFrame(...)
    # target_table = pd.DataFrame(...)

    # ë°ì´í„° ë¶„í• 
    def real_pred_compare(predictions,test_target,test_input):
        print(yellow("ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸[[ì‹¤ì œ ì˜ˆì¸¡ê°’ í™•ì¸]]ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸"))
        for idx,(pred_result,real,test_in) in enumerate(zip(predictions,test_target.values,test_input.values)):
            if idx < 4:
                str_real = "\t"
                str_pred = "\t"
                str_input = "\t"
                for i in list(real):
                    str_real = "\t".join("{:>8d}".format(int(val)) for val in real)
                for j in list(map(int,(pred_result))):
                    str_pred = "\t".join("{:>8d}".format(int(val)) for val in pred_result)
                for k in list(test_in):
                    str_input += str(k) + "\t"

                
                print(f"***** {idx} ë²ˆì§¸ test ê²°ê³¼ ***** ")
                print("ì¸í’‹ ì •ë³´"+"---"*200)
                print(f"ì¸í’‹ì¹¼ëŸ¼","\t".join((list(test_input.columns))),sep = "\t\t")
                print(f"***ì¸í’‹\t  {str_input}", sep='\t')
                print("ì•„ì›ƒí’‹ ì •ë³´"+"---"*200)
                print(f"  ","\t".join((list(test_target.columns))),sep = "\t\t")
                formatted_columns = "\t".join("{:>8s}".format(col) for col in list(test_target.columns))
                print(f"    \t{formatted_columns}")
                print(f"ì‹¤ì œ\t  {str_real}", sep='\t')
                print(f"ì˜ˆì¸¡\t  {str_pred}", sep='\t')

    def linear_regressor_prdict(train_input, train_target, test_input, test_target):
        from statistics import LinearRegression
        import numpy as np
        from sklearn.multioutput import MultiOutputRegressor
        from sklearn.linear_model import LinearRegression
        from sklearn.metrics import mean_squared_error
        from sklearn.metrics import mean_squared_error, r2_score
        from sklearn.model_selection import cross_val_score
        import joblib

        ## Linear Regression model ë¹„êµ
        lin_regressor = LinearRegression()
        multi_output_regressor_lin = MultiOutputRegressor(lin_regressor)
        multi_output_regressor_lin.fit(train_input, train_target)
        y_pred_lin = multi_output_regressor_lin.predict(test_input)
        mse = mean_squared_error(test_target, y_pred_lin)
        rmse = np.sqrt(mse)
        r2 = r2_score(test_target, y_pred_lin) 
        
        #### êµì°¨ê²€ì¦ 
        scores_cv = cross_val_score(multi_output_regressor_lin,train_input,train_target,scoring='neg_mean_squared_error',cv=10)
        rmse_cv = np.sqrt(-scores_cv)
        print(f"Linear regression model RMSE: {rmse:.2f}")
        print(f"Linear regression model R2 score: {r2:.2f}")
        print("\t ",f"LR cv score : {rmse_cv}")
        print("\t ",f"LR cv RMSE  average : {rmse_cv.mean():.2f}")
                # ëª¨ë¸ ì €ì¥
        joblib.dump(multi_output_regressor_lin, "Linear_model")
        print(f'ëª¨ë¸ì´ {"Linear_model"} ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨')
        predictions = multi_output_regressor_lin.predict(test_input)
        ModelTest.real_pred_compare(predictions,test_target,test_input)

    def knn_regressor_predict(train_input, train_target, test_input, test_target):
        import numpy as np
        from sklearn.multioutput import MultiOutputRegressor
        from sklearn.neighbors import KNeighborsRegressor
        from sklearn.metrics import mean_squared_error
        from xgboost import XGBRegressor
        from sklearn.metrics import mean_squared_error, r2_score
        from sklearn.model_selection import cross_val_score
        import joblib

        ## KNN regression model
        knn_regressor = KNeighborsRegressor(n_neighbors=3)
        ## Multi Output Setting
        multi_output_regressor_knn = MultiOutputRegressor(knn_regressor)
        multi_output_regressor_knn.fit(train_input, train_target)

        score = multi_output_regressor_knn.score(test_input, test_target)
        y_pred_knn = multi_output_regressor_knn.predict(test_input)
        mse = mean_squared_error(test_target, y_pred_knn)
        rmse = np.sqrt(mse)
        # R2 ìŠ¤ì½”ì–´ ê³„ì‚°
        r2 = r2_score(test_target, y_pred_knn)
        print(yellow(f'KNN(3) regression model score: {score}'))
        print(f'KNN(3) regression model RMSE: {rmse:.2f}')
        print(f'KNN regression model R2 score: {r2:.2f}')
        #### êµì°¨ê²€ì¦ 
        scores_cv = cross_val_score(multi_output_regressor_knn,train_input,train_target,scoring='neg_mean_squared_error',cv=10)
        rmse_cv = np.sqrt(-scores_cv)
        print("\t ",f"KNN cv score : {rmse_cv}")
        print("\t ",f"KNN cv RMSE average : {rmse_cv.mean():.2f}")
        # ëª¨ë¸ ì €ì¥
        joblib.dump(multi_output_regressor_knn, "KNN_model")
        print(f'ëª¨ë¸ì´ {"KNN_model"} ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨')
        predictions = multi_output_regressor_knn.predict(test_input)

        ModelTest.real_pred_compare(predictions,test_target,test_input)

    def xgboost_regressor_predict(train_input, train_target, test_input, test_target):
        import numpy as np
        from sklearn.multioutput import MultiOutputRegressor
        from sklearn.metrics import mean_squared_error
        from xgboost import XGBRegressor
        from sklearn.metrics import mean_squared_error, r2_score
        from sklearn.model_selection import cross_val_score
        import joblib

        xg_reg = XGBRegressor()
        multi_output_regressor_xg = MultiOutputRegressor(xg_reg)
        multi_output_regressor_xg.fit(train_input, train_target)

        score = multi_output_regressor_xg.score(test_input, test_target)
        y_pred_xg = multi_output_regressor_xg.predict(test_input)
        mse = mean_squared_error(test_target, y_pred_xg)
        rmse = np.sqrt(mse)
        # R2 ìŠ¤ì½”ì–´ ê³„ì‚°
        r2 = r2_score(test_target, y_pred_xg)
        print(yellow(f'XGB regression model score: {score}'))
        print(f'XGBoost(3) regression model RMSE: {rmse:.2f}')
        print(f'XGBoost regression model R2 score: {r2:.2f}')
        ### êµì°¯ê²€ì¦
        scores_cv = cross_val_score(multi_output_regressor_xg,train_input,train_target,scoring='neg_mean_squared_error',cv=10)
        rmse_cv = np.sqrt(-scores_cv)
        # ëª¨ë¸ ì €ì¥
        joblib.dump(multi_output_regressor_xg, "XG_model")
        print(f'ëª¨ë¸ì´ {"XG_model"} ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨')
        print("\t ",f"XGB cv score : {rmse_cv}")
        print("\t ",f"XGB cv RMSE average : {rmse_cv.mean():.2f}")
        predictions = multi_output_regressor_xg.predict(test_input)
        ModelTest.real_pred_compare(predictions,test_target,test_input)

    def randomforest_regressor_predict(train_input, train_target, test_input, test_target):
        import numpy as np
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.multioutput import MultiOutputRegressor
        from sklearn.metrics import mean_squared_error
        from xgboost import XGBRegressor
        from sklearn.metrics import mean_squared_error, r2_score
        from sklearn.model_selection import cross_val_score
        import joblib
        import os

        rf_reg = RandomForestRegressor(n_estimators=1, random_state=42)
        multi_output_regressor_rf = MultiOutputRegressor(rf_reg)
        multi_output_regressor_rf.fit(train_input, train_target)

        y_pred_rf = multi_output_regressor_rf.predict(test_input)
        mse = mean_squared_error(test_target, y_pred_rf)
        rmse = np.sqrt(mse)
        r2 = r2_score(test_target, y_pred_rf)

        print(yellow(f'RandomForest regression model RMSE: {rmse:.2f}'))
        print(f'RandomForest regression model R2 score: {r2:.2f}')

        # êµì°¨ ê²€ì¦
        scores_cv = cross_val_score(multi_output_regressor_rf, train_input, train_target, 
                                    scoring='neg_mean_squared_error', cv=10)
        rmse_cv = np.sqrt(-scores_cv)
        print("\t ", red(f"RF cv RMSE scores: {rmse_cv}"))
        print("\t ", green(f"RF cv RMSE average: {rmse_cv.mean():.2f}"))

        # R2 êµì°¨ ê²€ì¦
        r2_scores_cv = cross_val_score(multi_output_regressor_rf, train_input, train_target, 
                                    scoring='r2', cv=10)
        print("\t ", red(f"RF cv R2 scores: {r2_scores_cv}"))
        print("\t ", green(f"RF cv R2 average: {r2_scores_cv.mean():.2f}"))

        # ëª¨ë¸ ì €ì¥
        joblib.dump(multi_output_regressor_rf, "RF_model")
        print(f'ëª¨ë¸ì´ {"RF_model"} ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨')

        predictions = multi_output_regressor_rf.predict(test_input)
        ModelTest.real_pred_compare(predictions, test_target, test_input)


    
if __name__ == "__main__":
    import pandas as pd ,sys
    input_data = pd.read_csv('/Users/forrestdpark/Desktop/PDG/Python_/BerryMLcompetetion/BerryMachineLearning/ì˜ˆì„ ì—°ìŠµ_2023_tomato/Data/2023_smartFarm_AI_hackathon_dataset.csv')
    while True : 
        yellow("í”„ë¡œê·¸ë¨ ì‹œì‘")
        # DataPreprocessing.plotSetting()
        DataPreprocessing.dataInfo(input_data)
        print(green("ë‹¤ì‹œ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆë‹ˆê¹Œ?(yes =1, no=0): "))
        restart_query = int(sys.stdin.readline())
        if restart_query == 0:
            break     
    
