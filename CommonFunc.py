''' 
ğŸ“Œ Description :  

    - ê²½ì§„ëŒ€íšŒ ë°ì´í„° ì…‹ ë³´ê¸°ìœ„í•œ í•¨ìˆ˜ë“¤ ...
    - Visualization Class :
        0)
    - DataPreprocessing class :
        0) plotSetting
        1) DataInfo
        2) column_hist
        3) column_zero_find
        4) show_corr
    - ModelTest class 
        1) real_pred_compare
        2) linear_regressor_prdict
        3) knn_regressor_predict
        4) xgboost_regressor_predict
        5) randomforest_regressor_predict
ğŸ“Œ Date : 2024.06.02 
ğŸ“Œ Author : Forrest D Park 
ğŸ“Œ Update : 
    2024.08.07 by pdg : DataInfo í•¨ìˆ˜ ìƒì„±
    2024.08.23  by pdg : DataInfo -> ì‹œê³„ì—´ ë°ì´í„° ì¼ë•Œ ê·¸ë˜í”„ ì‹œê°í™” í•˜ëŠ” ê¸°ëŠ¥ ì¶”ê°€ 
        - ë¶„ì„ë•Œ ë°°ìš´ê±° ë‹¤ í”Œëí• ìˆ˜ìˆë„ë¡ í•¨ìˆ˜í™” í•˜ì. 

'''

def imd(image_address,width =700, height=300):
    print(f'<br><img src = "{image_address}" width="{width}" height="{height}"/><br>')
def colored_text(text, color='default', bold=False):
    '''
    #### ì˜ˆì‹œ ì‚¬ìš©ë²•
    print(colored_text('ì €ì¥ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.', 'red'))
    print(colored_text('ì €ì¥ í•©ë‹ˆë‹¤.', 'green'))
    default,red,green,yellow,blue, magenta, cyan, white, rest
    '''
    colors = {
        'default': '\033[99m',
        'red': '\033[91m',
        'green': '\033[92m',
        'yellow': '\033[93m',
        'blue': '\033[94m',
        'magenta': '\033[95m',  # ë³´ë¼ìƒ‰
        'cyan': '\033[96m',
        'white': '\033[97m',
        'black': '\033[30m',  # ê²€ì€ìƒ‰
        'bright_black': '\033[90m',  # ë°ì€ ê²€ì •ìƒ‰ (íšŒìƒ‰)
        'bright_red': '\033[91m',  # ë°ì€ ë¹¨ê°„ìƒ‰
        'bright_green': '\033[92m',  # ë°ì€ ì´ˆë¡ìƒ‰
        'bright_yellow': '\033[93m',  # ë°ì€ ë…¸ë€ìƒ‰
        'bright_blue': '\033[94m',  # ë°ì€ íŒŒë€ìƒ‰
        'bright_magenta': '\033[95m',  # ë°ì€ ë³´ë¼ìƒ‰
        'bright_cyan': '\033[96m',  # ë°ì€ ì²­ë¡ìƒ‰
        'bright_white': '\033[97m',  # ë°ì€ í°ìƒ‰
        'reset': '\033[0m'
    }

    # ë¬´ì§€ê°œ ìƒ‰ ì¶”ê°€ (RGB ê°’ ì‚¬ìš©)
    rainbow_colors = [
        '\033[38;2;255;0;0m',  # ë¹¨ê°„ìƒ‰
        '\033[38;2;255;127;0m',  # ì£¼í™©ìƒ‰
        '\033[38;2;255;255;0m',  # ë…¸ë€ìƒ‰
        '\033[38;2;0;255;0m',  # ì´ˆë¡ìƒ‰
        '\033[38;2;0;255;127m',  # ì²­ë¡ìƒ‰
        '\033[38;2;0;0;255m',  # íŒŒë€ìƒ‰
        '\033[38;2;127;0;255m',  # ë³´ë¼ìƒ‰
    ]

    # ë¬´ì§€ê°œ ìƒ‰ ì¶”ê°€ (ìƒ‰ìƒ ëª…ì¹­)
    colors.update({
        'rainbow_red': rainbow_colors[0],
        'rainbow_orange': rainbow_colors[1],
        'rainbow_yellow': rainbow_colors[2],
        'rainbow_green': rainbow_colors[3],
        'rainbow_cyan': rainbow_colors[4],
        'rainbow_blue': rainbow_colors[5],
        'rainbow_magenta': rainbow_colors[6],
    })

    color_code = colors.get(color, colors['default'])
    bold_code = '\033[1m' if bold else ''
    reset_code = colors['reset']

    return f"{bold_code}{color_code}{text}{reset_code}"
def blue(str, b=False):return colored_text(str, 'blue', bold=b)
def yellow(str, b=False):return colored_text(str, 'yellow', bold=b)
def red(str, b=False):return colored_text(str, 'red', bold=b)
def green(str, b=False):return colored_text(str, 'green', bold=b)
def magenta(str, b=False):return colored_text(str, 'magenta', bold=b)
# ë¬´ì§€ê°œ ìƒ‰ í•¨ìˆ˜ ì¶”ê°€
def rainbow_red(str, b=False):return colored_text(str, 'rainbow_red', bold=b)
def rainbow_orange(str, b=False):return colored_text(str, 'rainbow_orange', bold=b)
def rainbow_yellow(str, b=False):return colored_text(str, 'rainbow_yellow', bold=b)
def rainbow_green(str, b=False):return colored_text(str, 'rainbow_green', bold=b)
def rainbow_cyan(str, b=False):return colored_text(str, 'rainbow_cyan', bold=b)
def rainbow_blue(str, b=False):return colored_text(str, 'rainbow_blue', bold=b)
def rainbow_magenta(str, b=False):return colored_text(str, 'rainbow_magenta', bold=b)
# ê²€ì€ìƒ‰ í•¨ìˆ˜ ì¶”ê°€
def black(str, b=False):return colored_text(str, 'black', bold=b)
def rainbow_text(text,bold =False):
    """í…ìŠ¤íŠ¸ë¥¼ ë¬´ì§€ê°œìƒ‰ìœ¼ë¡œ í•œ ê¸€ìì”© ì¶œë ¥í•©ë‹ˆë‹¤."""
    rainbow_colors = [
        '\033[38;2;255;0;0m',  # ë¹¨ê°„ìƒ‰
        '\033[38;2;255;127;0m',  # ì£¼í™©ìƒ‰
        '\033[38;2;255;255;0m',  # ë…¸ë€ìƒ‰
        '\033[38;2;0;255;0m',  # ì´ˆë¡ìƒ‰
        '\033[38;2;0;255;127m',  # ì²­ë¡ìƒ‰
        '\033[38;2;0;0;255m',  # íŒŒë€ìƒ‰
        '\033[38;2;127;0;255m',  # ë³´ë¼ìƒ‰
    ]
    colored_text = ''
    for i, char in enumerate(text):
        colored_text += rainbow_colors[i % len(rainbow_colors)] + char
    colored_text += '\033[0m'  # ìƒ‰ìƒ ì´ˆê¸°í™”
    bold_code = '\033[1m' if bold else ''
    return f"{bold_code}{colored_text}"


## google api ì‚¬ìš©í•˜ì—¬ ì£¼ì†Œ ì°¾ê¸° 
def find_location(test,save_ok = False, save_file_path=""):
    import googlemaps
    import pandas as pd
    my_key="AIzaSyB8IQ9_T6w74by5ctA2lHirC-_jHR0OmKI" ## google 
    maps = googlemaps.Client(key=my_key)
    
    # ì§€ë„ ê·¸ë¦¬ê¸°
    import folium
    import numpy as np
    from folium.features import CustomIcon
    total_map = folium.Map(
        location=[37.55, 126.98],
        zoom_start=12,
    )
    idolbom_icoon_address = "/Users/forrestdpark/Desktop/PDG/Python_/BerryMLcompetetion/ê³µëª¨ì „/ì„œìš¸GovTech/ëŒë´„ì„œë¹„ìŠ¤/idolbomi_02.png"

    icon = CustomIcon(idolbom_icoon_address, icon_size=(40, 40))
    df = pd.DataFrame(columns=['ì„¼í„°ëª…', 'ìœ„ë„', 'ê²½ë„', 'ì£¼ì†Œ'])
    for i, center in enumerate(test['ì„¼í„°ëª…']):
        if i != 100000:
            try:
                
                geo_location = maps.geocode(center, language='ko')[0].get('geometry')  # í•œê¸€ ì£¼ì†Œ ì„¤ì •
                lat = geo_location['location']['lat']
                lng = geo_location['location']['lng']
                address_kor = maps.geocode(center, language='ko')[0].get('formatted_address')
                
                # print(f"{center} ë§ˆì»¤ ì¶”ê°€ {maps.geocode(center, language='ko')[0].get('formatted_address')}")  # í•œê¸€ ì£¼ì†Œ ì¶œë ¥
                
                # DataFrameì— ë°ì´í„° ì¶”ê°€ (concat ì‚¬ìš©)
                new_row = pd.DataFrame({'ì„¼í„°ëª…': [center], 'ìœ„ë„': [lat], 'ê²½ë„': [lng], 'ì£¼ì†Œ': [address_kor]})
                df = pd.concat([df, new_row], ignore_index=True)
                marker = folium.Marker(
                    [lat, lng],  # ê° ì„¼í„°ì˜ ì¢Œí‘œ ì‚¬ìš©
                    radius=20,
                    # icon=icon,
                    color='brown',
                    fill=True,
                    fill_color='red',
                    fill_opacity=0.8,
                    popup=f"<pre>{center} <pre>",
                    tooltip=f"{center}<br>{address_kor}"
                )
                total_map.add_child(marker)  # ë§ˆì»¤ë¥¼ ì§€ë„ì— ì¶”ê°€
            except IndexError:
                print(f"{center}ì˜ ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                new_row = pd.DataFrame({'ì„¼í„°ëª…': [center], 'ìœ„ë„': [np.nan], 'ê²½ë„': [np.nan], 'ì£¼ì†Œ': [np.nan]})
                df = pd.concat([df, new_row], ignore_index=True)
            # DataFrameì„ CSV íŒŒì¼ë¡œ ì €ì¥
    if save_ok:
        print(yellow("íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤."))
        df.to_csv(save_file_path, index=False, encoding='utf-8')
    return total_map

def Analysis_title(Title):
    random_imoticon = ["ğŸ™€","ğŸ‘»","ğŸ˜œ","ğŸ¤—","ğŸ™„","ğŸ¤‘","ğŸ¤–"]
    import numpy as np
    import random
    imo = random_imoticon[random.randrange(1,len(random_imoticon))]
    print(rainbow_green(f"âœ»âœ»âœ»âœ»______{imo*1} {Title} {imo*1}______âœ»âœ»âœ»âœ»",True))

def df_display_centered(df):
    from IPython.display import display, HTML
    import pandas as pd 
    if type(df) != type(pd.DataFrame()):
        df=pd.DataFrame(df)
    display(HTML('<div style="text-align: center; margin-left: 50px;">{}</div>'.format(df.to_html().replace('<table>', '<table style="margin: 0 auto;">'))))

def data_watch_one(start_, dataInfo=False,data_folder_path="./ë°ì´í„°íŒŒì¼"):
    ## Data Fetching range
    start_data  =start_
    end_data =start_data+1
    
    Analysis_title(f"{start_data}-{end_data} ë²ˆ íŒŒì¼ ë°ì´í„° ë³´ê³  ë¶„ì„ by Forrest.D.Park")
    data_dict=DataPreprocessing.data_fetch(data_folder_path,start_data,end_data)
    
    ## data watching
    for i in range(len(data_dict.keys())):
        data_num= sorted(data_dict.keys())[i]
        print(yellow(f"\n\n{data_num} íŒŒì¼ì˜ ë°ì´í„° í”„ë ˆì„.tail() "))
        # í™”ë©´ ê°€ìš´ë° ì •ë ¬í•˜ì—¬ ì¶œë ¥
        df_display_centered(DataPreprocessing.key_selector(data_dict, i).tail())
        if dataInfo:
            DataPreprocessing.plotSetting()
            DataPreprocessing.dataInfo2(DataPreprocessing.key_selector(data_dict,i))
    return data_dict

def data_watch_range(start_,end_, dataInfo = False,data_folder_path="./ë°ì´í„°íŒŒì¼"):
    ## Data Fetching
    data_folder_path=data_folder_path
    start_data  =start_
    end_data =end_
    Analysis_title(f"{start_data}-{end_data} ë²ˆ íŒŒì¼ ë°ì´í„° ë³´ê³  ë¶„ì„ by Forrest.D.Park")
    data_dict=DataPreprocessing.data_fetch(data_folder_path,start_data,end_data)
    for i in range(len(data_dict.keys())):
        data_num= sorted(data_dict.keys())[i]
        print(yellow(f"\n\n{data_num} íŒŒì¼ì˜ ë°ì´í„° í”„ë ˆì„.tail() "))
        # í™”ë©´ ê°€ìš´ë° ì •ë ¬í•˜ì—¬ ì¶œë ¥
        df_display_centered(DataPreprocessing.key_selector(data_dict, i).tail())
        if dataInfo:
            DataPreprocessing.plotSetting(pltStyle='default')
            DataPreprocessing.dataInfo2(DataPreprocessing.key_selector(data_dict,i))
    return data_dict

def drawing_graph_01():
    # ì—¬ê°€ë¶€ ê·¸ë˜í”„ ë”°ë¼ ê·¸ë¦¬ê¸° 
    import pandas as pd
    import matplotlib.pyplot as plt

    columns = ['ë…„ë„', 'ì‹œê°„ì œ', 'ì¢…ì¼ì œ', 'ê¸°íƒ€', 'ì´ìš©ê°€êµ¬ê³„', 'ê°€êµ¬ë³„ì›”í‰ê· ì´ìš©ì‹œê°„']

    # ë°ì´í„° ì¶”ê°€
    
    data = [
        {'ë…„ë„': 2019, 'ì‹œê°„ì œ': 66783, 'ì¢…ì¼ì œ': 3702, 'ê¸°íƒ€': 0, 'ì´ìš©ê°€êµ¬ê³„': 70485, 'ê°€êµ¬ë³„ì›”í‰ê· ì´ìš©ì‹œê°„': 71.8},
        {'ë…„ë„': 2020, 'ì‹œê°„ì œ': 56525, 'ì¢…ì¼ì œ': 3138, 'ê¸°íƒ€': 0, 'ì´ìš©ê°€êµ¬ê³„': 59663, 'ê°€êµ¬ë³„ì›”í‰ê· ì´ìš©ì‹œê°„': 87.4},
        {'ë…„ë„': 2021, 'ì‹œê°„ì œ': 57454, 'ì¢…ì¼ì œ': 2617, 'ê¸°íƒ€': 11718, 'ì´ìš©ê°€êµ¬ê³„': 71789, 'ê°€êµ¬ë³„ì›”í‰ê· ì´ìš©ì‹œê°„': 87.9},
        {'ë…„ë„': 2022, 'ì‹œê°„ì œ': 61138, 'ì¢…ì¼ì œ': 2760, 'ê¸°íƒ€': 14314, 'ì´ìš©ê°€êµ¬ê³„': 78212, 'ê°€êµ¬ë³„ì›”í‰ê· ì´ìš©ì‹œê°„': 83.1},
        {'ë…„ë„': 2023, 'ì‹œê°„ì œ': 66515, 'ì¢…ì¼ì œ': 1890, 'ê¸°íƒ€': 17695, 'ì´ìš©ê°€êµ¬ê³„': 86100, 'ê°€êµ¬ë³„ì›”í‰ê· ì´ìš©ì‹œê°„': 85.6},
    ]

    df_test = pd.DataFrame(data, columns=columns)

    # ì‹œê°í™”
    fig, ax1 = plt.subplots(figsize=(10, 6))

    # bar plot for ì‹œê°„ì œ, ì¢…ì¼ì œ (ì˜†ìœ¼ë¡œ ë‚˜ë€íˆ)
    width = 0.2  # ë§‰ëŒ€ ë„ˆë¹„ ì¡°ì ˆ
    bars_ì‹œê°„ì œ =ax1.bar(df_test['ë…„ë„'] - width/2, df_test['ì‹œê°„ì œ'], width, label='ì‹œê°„ì œ', color='skyblue')

    # ë°” í”Œë¡¯ ìœ„ì— ë°ì´í„° ê°’ í‘œì‹œ (í…ìŠ¤íŠ¸ë¡œ ë¶™ì´ê¸°)
    for i, bar in enumerate(bars_ì‹œê°„ì œ):
        height = bar.get_height()
        x_pos = bar.get_x()
        bar_width = bar.get_width()
        ax1.text(x_pos + bar_width / 2, height, f'{height:.0f}', ha='center', va='bottom', fontsize=8,color='blue')
        
        
        
    bars_ì¢…ì¼ì œ =ax1.bar(df_test['ë…„ë„'] + width/2, df_test['ì¢…ì¼ì œ'], width, label='ì¢…ì¼ì œ', color='lightcoral')
    # ë°” í”Œë¡¯ ìœ„ì— ë°ì´í„° ê°’ í‘œì‹œ (í…ìŠ¤íŠ¸ë¡œ ë¶™ì´ê¸°)
    for i, bar in enumerate(bars_ì¢…ì¼ì œ):
        height = bar.get_height()
        x_pos = bar.get_x()
        bar_width = bar.get_width()
        ax1.text(x_pos + bar_width / 2, height, f'{height:.0f}', ha='center', va='bottom', fontsize=8)

    bars_ê¸°íƒ€ =ax1.bar(df_test['ë…„ë„'] + width/2*3, df_test['ê¸°íƒ€'], width, label='ê¸°íƒ€', color='lightgreen')

    # ë°” í”Œë¡¯ ìœ„ì— ë°ì´í„° ê°’ í‘œì‹œ (í…ìŠ¤íŠ¸ë¡œ ë¶™ì´ê¸°)
    for i, bar in enumerate(bars_ê¸°íƒ€):
        height = bar.get_height()
        x_pos = bar.get_x()
        bar_width = bar.get_width()
        ax1.text(x_pos + bar_width / 2, height, f'{height:.0f}', ha='center', va='bottom', fontsize=8)

        
    ax1.plot(df_test['ë…„ë„'], df_test['ì´ìš©ê°€êµ¬ê³„']*1.05, label='ì´ìš©ê°€êµ¬ê³„', marker='o', linestyle='-')
    # ì„  ê·¸ë˜í”„ ì ì— ë°ì´í„° ê°’ í‘œì‹œ (í…ìŠ¤íŠ¸ë¡œ ë¶™ì´ê¸°)


    for i, txt in enumerate(df_test['ì´ìš©ê°€êµ¬ê³„']):
        ax1.text(df_test['ë…„ë„'][i], txt + 5500, f'{txt:.0f}', ha='center', va='bottom', fontsize=8,color='black')
    ax1.set_xlabel('ë…„ë„')
    ax1.set_ylabel('ì´ìš© ê°€êµ¬ ìˆ˜')
    ax1.set_title('ì‹œê°„ì œ, ì¢…ì¼ì œ ì´ìš© ê°€êµ¬ ìˆ˜ ë³€í™” (2019-2023)')
    ax1.legend(loc='upper left')
    ax1.set_ylim([0,110000])
    # twin axes for line plot
    ax2 = ax1.twinx()
    ax2.plot(df_test['ë…„ë„'], df_test['ê°€êµ¬ë³„ì›”í‰ê· ì´ìš©ì‹œê°„'], label='ê°€êµ¬ë³„ ì›”í‰ê·  ì´ìš© ì‹œê°„', marker='o', linestyle='-', color='darkgreen')
    for i, txt in enumerate(df_test['ê°€êµ¬ë³„ì›”í‰ê· ì´ìš©ì‹œê°„']):
        ax2.text(df_test['ë…„ë„'][i], txt + 1.5, f'{txt:.0f}', ha='center', va='bottom', fontsize=9, color='darkgreen')
    ax2.set_ylabel('ê°€êµ¬ë³„ ì›”í‰ê·  ì´ìš© ì‹œê°„ (ë¶„)')  # yì¶• ë¼ë²¨ ì¶”ê°€
    ax2.spines['right'].set_position(('outward', 0))  # ì˜¤ë¥¸ìª½ ì¶• ìœ„ì¹˜ ì¡°ì •
    ax2.tick_params(axis='y', labelcolor='darkgreen')  # yì¶• ë¼ë²¨ ìƒ‰ìƒ ë³€ê²½
    ax2.legend(loc='upper right')
    ax2.set_ylim([60,150])
    plt.grid(True)
    plt.show()

def ì‹œê³„ì—´ê·¸ë˜í”„_ì¹¼ëŸ¼ì•ˆì—ì„œíŠ¹ì •ë°ì´í„°ì—í•´ë‹¹í•˜ëŠ”_ë‹¤ë¥¸ì—´ë“¤(df,group_col="",selected_row="",target_col = [''],ê¸°ì¤€ì—°ì›”_str = "ê¸°ì¤€ì—°ì›”"):
    import matplotlib.pyplot as plt, pandas as pd
    import platform
    from matplotlib import font_manager, rc
    # unicode ì„¤ì •
    ê¸°ì¤€ì—°ì›”_str = "ê¸°ì¤€ì—°ì›”"
    target = df[df[group_col]==selected_row]
    print(yellow(f"Taget data : {selected_row}"))
    
    numeric_columns=target.select_dtypes(include=['number']).columns.tolist()
    print(yellow(f"numeric colums of taget data : {numeric_columns}"))
    
    target[ê¸°ì¤€ì—°ì›”_str] = pd.to_datetime(target[ê¸°ì¤€ì—°ì›”_str], format='%Y%m')

    df_display_centered(target.head(1))
    def visualize_01(target,numeric_columns,target_col):
        ### íŠ¹ì • ì¹¼ëŸ¼ ì‹œê°í™” ####
        plt.figure(figsize=(15,8))
        for column in numeric_columns:
            if column== ê¸°ì¤€ì—°ì›”_str:
                continue
            # print(column)
            if column in target_col:
                plt.plot(target[ê¸°ì¤€ì—°ì›”_str],target[column],label=column, marker = 'o')
        # plt.plot(target['ê¸°ì¤€ì—°ì›”'],target[target_col],label=target_col, marker = 'o') 
        plt.title(f'{selected_row} - ì‹œê°„ì— ë”°ë¥¸ {target_col} ë³€í™”')
        plt.xlabel('ê¸°ì¤€ì—°ì›”')
        plt.ylabel(target_col)
        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))
        plt.xticks(rotation=45)
        plt.grid(True, linestyle='--', alpha=0.7)

        # xì¶• ë‚ ì§œ í¬ë§· ì„¤ì •
        plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))
        plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.MonthLocator(interval=3))
        plt.tight_layout()
        plt.show()
    visualize_01(target,numeric_columns,target_col)
    visualize_01(target,numeric_columns,['ì‹ ê·œíšŒì›ìˆ˜','ì‹ ê·œì•„ë™ìˆ˜','ëŒ€ê¸°ì •íšŒì›ìˆ˜','ì›¹íšŒì›ìˆ˜'])


def data_column_info(data_column_info_str = ""):
    if data_column_info_str:
        data_column_info = data_column_info_str
    else : 
        data_column_info=\
    '''
    - Molecule ChEMBL ID: ChEMBL ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¶„ìì˜ ê³ ìœ  ì‹ë³„ì     
    - Standard Type: ì¸¡ì •ëœ í™œì„±ì˜ ìœ í˜• (ì—¬ê¸°ì„œëŠ” IC50)        
    - Standard Relation: í™œì„± ê°’ì˜ ê´€ê³„ (ì—¬ê¸°ì„œëŠ” '=', ì •í™•í•œ ê°’ì„ ì˜ë¯¸)       
    - Standard Value: í‘œì¤€í™”ëœ í™œì„± ê°’         
    - Standard Units: í™œì„± ê°’ì˜ ë‹¨ìœ„ (ì—¬ê¸°ì„œëŠ” nM, ë‚˜ë…¸ëª°)       
    - pChEMBL Value: -log10(ëª° ë‹¨ìœ„ì˜ í™œì„± ê°’). í™œì„±ì˜ í¬ê¸°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í‘œì¤€í™”ëœ ê°’           
    - Assay ChEMBL ID: í™œì„±ì„ ì¸¡ì •í•œ ì‹¤í—˜ì˜ ê³ ìœ  ì‹ë³„ì         
    - Target ChEMBL ID: ëª©í‘œ ë‹¨ë°±ì§ˆì˜ ê³ ìœ  ì‹ë³„ì        
    - Target Name: ëª©í‘œ ë‹¨ë°±ì§ˆì˜ ì´ë¦„           
    - Target Organism: ëª©í‘œ ë‹¨ë°±ì§ˆì´ ì†í•œ ìƒë¬¼ì¢…            
    - Target Type: ëª©í‘œì˜ ìœ í˜• (ì—¬ê¸°ì„œëŠ” ë‹¨ì¼ ë‹¨ë°±ì§ˆ)          
    - Document ChEMBL ID: ì´ ë°ì´í„°ì˜ ì¶œì²˜ ë¬¸ì„œì˜ ê³ ìœ  ì‹ë³„ì        
    - IC50_nM: IC50 ê°’ (ë‚˜ë…¸ëª° ë‹¨ìœ„)       
    - pIC50: -log10(IC50). IC50ì˜ ìŒì˜ ë¡œê·¸ ê°’ìœ¼ë¡œ, í™œì„±ì˜ í¬ê¸°ë¥¼ ë‚˜íƒ€ëƒ„          
    - Smiles: í™”í•©ë¬¼ì˜ êµ¬ì¡°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” SMILES ë¬¸ìì—´ '''        
    lines = data_column_info.strip().split('\n')
    for line in lines:
        parts = line.split(':', 1)  # ì½œë¡  ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
        if len(parts) == 2:
            left_part = parts[0].strip()
            right_part = parts[1].strip()
            print(rainbow_orange(f"{left_part}:",True), rainbow_cyan(f"{right_part}"))
        else:
            print(line) 


def drop_single_data_col(df):
    to_drop_columns = []

    for order,i in enumerate(df.columns):
        if len(df[i].unique())==1:
            print(yellow(f"   -{order}.{i}ì¹¼ëŸ¼ì˜ ë°ì´í„°ëŠ” í•˜ë‚˜ë¿ì…ë‹ˆë‹¤."),rainbow_cyan(" ê°’:"),rainbow_orange(f"{df[i].unique()[0]}"))
            to_drop_columns.append(i)
    df = df.drop(columns = to_drop_columns)
    print(blue("--- ë°ì´í„°ê°€ í•˜ë‚˜ë¿ì¸ ì¹¼ëŸ¼ì„ ì‚­ì œí•œ ë°ì´í„°í”„ë ˆì„"))
    return df

class DataPreprocessing:
    def __init__(self) -> None:
        pass
    
    def key_selector(data_dict,num=0):
        for order,i in enumerate(sorted(data_dict.keys())):
            print(rainbow_magenta(f"\t{order} ë²ˆì§¸ : {i}"))
        data_name= sorted(data_dict.keys())[num]
        print(rainbow_yellow(f"{num}ë²ˆì§¸ ë°ì´í„°ë¥¼ {data_name}í˜¸ì¶œí•©ë‹ˆë‹¤. "))
        return data_dict[data_name]
    
    def data_fetch(data_folder_path,start,end):
        import os,pandas as pd
        from tqdm import tqdm  # ì§„í–‰ ìƒí™© í‘œì‹œ ë¼ì´ë¸ŒëŸ¬ë¦¬
        data_dict ={}
        count = 1
        with tqdm(total=100, desc="Data File ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..", bar_format="{desc}:{percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]", colour='green') as pbar:
            for filename in os.listdir(data_folder_path):
                file_number = int(filename.split(".")[0])
                if file_number in range(start, end):
                    file_path = os.path.join(data_folder_path, filename)
                    if filename.endswith(".csv"):
                        data_dict[filename] = pd.read_csv(file_path)
                    elif filename.endswith((".xls", ".xlsx")):
                        data_dict[filename] = pd.read_excel(file_path)
                    else:
                        print(f"Unsupported file type: {filename}")
                    
                    pbar.update(count)
                    count += 3

        return data_dict
    
    def plotSetting(pltStyle="seaborn-v0_8"):
        '''
        # Fucntion Description : Plot í•œê¸€í™” Setting
        # Date : 2024.06.05
        # Author : Forrest D Park 
        # update : 
        '''

        
        import warnings ;warnings.filterwarnings('ignore')
        import sys ;sys.path.append("../../../")
        import os 
        print(blue(f"â— í˜„ì¬ ê²½ë¡œì˜ í´ë” ëª©ë¡ --",True))
        for i,file in enumerate(os.listdir(os.getcwd())):
            if os.path.isdir(os.path.join(os.getcwd(),file)):
                print(yellow(f"  {i}. {str(os.path.join(os.getcwd(),file))}"))
        sys.path.append("../")
        sys.path.append("../../")
        
        print(blue(f"â— ì£¼í”¼í„° ê°€ìƒí™˜ê²½ ì²´í¬ : {os.environ['CONDA_DEFAULT_ENV']}",True))
        print(blue(f"â— Python ì„¤ì¹˜ ê²½ë¡œ:{sys.executable}",True))
        print(blue(f"â— Graph í•œê¸€í™” Setting",True))
        
  
        # graph style seaborn
        import matplotlib.pyplot as plt # visiulization
        import platform
        from matplotlib import font_manager, rc # rc : í°íŠ¸ ë³€ê²½ ëª¨ë“ˆfont_manager : í°íŠ¸ ê´€ë¦¬ ëª¨ë“ˆ
        plt.style.use(pltStyle)
        plt.rcParams['axes.unicode_minus'] = False# unicode ì„¤ì •
        if platform.system() == 'Darwin': rc('font', family='AppleGothic') # osê°€ macos
        elif platform.system() == 'Windows': # osê°€ windows
            path = 'c:/Windows/Fonts/malgun.ttf' 
            font_name = font_manager.FontProperties(fname=path).get_name()
            rc('font', family=font_name)
        else:
            print("Unknown System")
        print(colored_text("â— OS platform í•œê¸€ ì„¸íŒ…ì™„ë£Œ",'blue',bold=True))
        # print(rainbow_green(f"âœ»âœ»âœ»âœ»______{imo*1} {Title} {imo*1}______âœ»âœ»âœ»âœ»",True))

    
    
    def dataInfo2(df, replace_Nan=False, PrintOutColnumber = 0,nanFillValue=0, graphPlot=True):
        ### Description  : ìƒˆìš´ ë°ì´í„° ì •ë³´ ê¹Œê¸° í•¨ìˆ˜
        import pandas as pd
        column_count = len(df.columns)
        row_count = len(df.index)
        nul_count  = df.isnull().sum().sum()
        value_kind_limit =10
        under_limit_columns =[]
        if PrintOutColnumber ==0 :
            PrintOutColnumber = column_count
        print(yellow(f" â— Column  : {column_count} ê°œ "))
        for num,i in enumerate(df.columns.tolist()):
            if num%5 != 0: 
                print(rainbow_orange(f"   {i}"), end=", ")
            else:
                print(rainbow_orange(f"\n   {i}"), end=", ")
        else:print("")
        print(yellow(f" â— Row size    : {row_count} ê°œ"))
        print(yellow(f" â— Null count   : {nul_count} ê°œ"))
        
        
        for idx, col in enumerate(df.columns):
            if df[f"{col}"].isnull().sum():
                print(f"   => {idx}ë²ˆì§¸.[{col}]ì»¬ëŸ¼ : ",f"null {df[f'{col}'].isnull().sum()} ê°œ,\t not null {df[f'{col}'].notnull().sum()} ê°œ")
                ## Null data fill
                if replace_Nan : ## nan ì„ 0 ìœ¼ë¡œ ëŒ€ì²´ 
                    df[col].fillna(value=nanFillValue, inplace=True)  
        print(yellow(" â— ì¹¼ëŸ¼ë³„ ë°ì´í„° ì¤‘ë³µì²´í¬"))

        for idx, col in enumerate(df.dtypes.keys()):
            value_counts = df[col].value_counts()
            under_limit_columns.append(col)
            print(yellow(f"   â–¡ {idx+1}ë²ˆì§¸ ì¹¼ëŸ¼ \" {col}\"  íƒ€ì… {df.dtypes[col]})"),\
                            red(f"\n    {len(df[col].unique())}"),\
                            green(f"\t/{len(df[col])} ")+ "\t[uniq/raw]",\
            )
            
            ### Value count ê°’ ë¶„í¬ í™•ì¸
            check_df = pd.DataFrame(
                    {
                        f'\"{col}\" ì¹¼ëŸ¼ì˜ ì¤‘ë³µê°’': value_counts.index.tolist(),
                        'ê°œìˆ˜ë¶„í¬': value_counts.values.tolist()
                    },
                    index=range(1, len(value_counts) + 1)
    )

            df_display_centered(check_df.head(10))
            
            # ê·¸ë˜í”„ ìƒì„±
            import matplotlib.pyplot as plt
            import seaborn as sns
            
            if len(check_df.index) <10 :
                plt.figure(figsize=(8, 6))  # ê·¸ë˜í”„ í¬ê¸° ì„¤ì •
                labels = value_counts.index.tolist()
                for i, label in enumerate(labels):
                    # labelì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                    label = str(label)
                    if len(label) > 10:
                        labels[i] = label[:10] + "..."
                colors = sns.color_palette("pastel", len(value_counts.values)) 
                # í¼ì„¼íŠ¸ì™€ ì‹¤ì œ ìˆ˜ì¹˜ í•¨ê»˜ í‘œì‹œ
                def make_autopct(values):
                    def my_autopct(pct):
                        total = sum(values)
                        val = int(round(pct * total / 100.0))
                        return f'{pct:.1f}% ({val:d})'
                    return my_autopct

                plt.pie(value_counts.values, labels=labels, autopct=make_autopct(value_counts.values), startangle=90, colors=colors)
                plt.title(f"{col} ì»¬ëŸ¼ ê°’ ë¶„í¬ (íŒŒì´ ì°¨íŠ¸)", fontsize=13)
                plt.axis('equal')  # íŒŒì´ ì°¨íŠ¸ë¥¼ ì›í˜•ìœ¼ë¡œ ìœ ì§€
                plt.show()  # ê·¸ë˜í”„ ì¶œë ¥
                if graphPlot :DataPreprocessing.column_hist(df,col)
            else:
                plt.figure(figsize=(14, 4))  # ê·¸ë˜í”„ í¬ê¸° ì„¤ì •
                sns.barplot(x=value_counts.index, y=value_counts.values, palette="viridis") 
                plt.title(f"{col} ì»¬ëŸ¼ ê°’ ë¶„í¬",fontsize=13)  # ê·¸ë˜í”„ ì œëª© ì„¤ì •
                # xì¶• ë ˆì´ë¸” ê¸¸ì´ê°€ 10 ê¸€ì ì´ìƒì´ë©´ ...ìœ¼ë¡œ í‘œí˜„
                for label in plt.gca().get_xticklabels():
                    label = str(label)
                    if len(label) > 10:
                        label = label[:10] + "..."  # ë³€ê²½
                        # label.set_text(label[:10] + "...")
                plt.ylabel("ê°œìˆ˜")  # yì¶• ë ˆì´ë¸” ì„¤ì •
                plt.xticks(rotation=45)  # xì¶• ë ˆì´ë¸” íšŒì „
                plt.tight_layout()  # ë ˆì´ë¸” ê°„ ê°„ê²© ì¡°ì •
                plt.show()  # ê·¸ë˜í”„ ì¶œë ¥
                if graphPlot :DataPreprocessing.column_hist(df,col)

        else: 
            print(red("\t[RESULT]"),"ğŸ™€ğŸ™€ğŸ™€"*10)
            print(yellow(f"\tğŸŸ¦{value_kind_limit}ê°œì´í•˜ì˜ ê°’ ì¢…ë¥˜ë¥¼ ê°€ì§€ëŠ” ì¹¼ëŸ¼ "))
            # print(red(str(under_limit_columns)))
            for col in under_limit_columns:
                print("\t\t-",yellow(f"{col}:{len(df[col].unique())}: {df[col].unique().tolist()}"))
            else:
                
                print("\t",red(f"ì´ {len(under_limit_columns)}ê°œ"))
                print(rainbow_cyan(" ---- data frame ì˜ ì •ë³´ ì¡°ì‚¬ ì™„ë£Œ -----}",True))
                return under_limit_columns
                

    
    
    
    def column_hist(df,col):
        import pandas as pd
        import matplotlib.pyplot as plt
        import seaborn as sns
        import numpy as np
        num_cols = df.select_dtypes(include=np.number).columns  # ìˆ«ìí˜• ì¹¼ëŸ¼ë§Œ ì„ íƒ

        if col in num_cols:
            plt.figure(figsize=(5, 4))
            # íˆìŠ¤í† ê·¸ë¨ê³¼ KDE ë™ì‹œì— ê·¸ë¦¬ê¸°
            sns.histplot(df[col], kde=True, bins=30)
            plt.title(f"{col} -Histogram", fontsize=15)
            plt.xlabel(col, fontsize=12)
            plt.ylabel("Density", fontsize=12)
             # ê¸°ìˆ  í†µê³„ì¹˜ ê³„ì‚°
            mean_val = df[col].mean()
            median_val = df[col].median()
            std_val = df[col].std()
            min_val = df[col].min()
            max_val = df[col].max()

            # ê·¸ë˜í”„ì— ê¸°ìˆ  í†µê³„ì¹˜ ì¶”ê°€
            stats_text = (
            
            f"""í‰ê· ê°’ : {mean_val:<10.1f}
            ì¤‘ì•™ê°’ : {median_val:<10.1f}
            í‘œì¤€í¸ì°¨: {std_val:<10.1f}
            ìµœì†Œê°’ : {min_val:<10.1f}
            ìµœëŒ€ê°’ : {max_val:<10.1f}"""
            )
            
            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì¡°ì • (ì¢Œí•˜ë‹¨)
            plt.text(x=0.95, y=0.95, s=stats_text, fontsize=8, 
                    ha='right', va='top', transform=plt.gca().transAxes, 
                    bbox=dict(facecolor='white', alpha=0.7))
            plt.show()
        else: 
            print(colored_text("ìˆ«ìí˜•ë°ì´í„°ê°€ ì•„ë‹™ë‹ˆë‹¤",'red',bold=True))
            # sns.histplot(df[col], kde=True, bins=len(df[col].unique()))
            # plt.xticks(rotation=45)  # xì¶• ë¼ë²¨ì„ 45ë„ ê¸°ìš¸ì…ë‹ˆë‹¤
            # plt.show()

    # ê° ì»¬ëŸ¼ë³„ 0 ê°’ ë¹„ìœ¨,ê°¯ìˆ˜ë³´ê¸°
    def column_zero_find(data):
        import matplotlib.pyplot as plt
        dataCount = data.columns.shape[0]
        for i in range(dataCount):

            data.columns[i]
            count_zero = (data[data.columns[i]] == 0).sum()
            count_non_zero = (data[data.columns[i]] != 0).sum()
            sizes = [count_zero, count_non_zero]
            labels = [f'{count_zero}ê°œ\n0ì¸ ë°ì´í„°', f'{count_non_zero}ê°œ\n0ì´ ì•„ë‹Œ ë°ì´í„°']
            colors = ['#ff9999','#66b3ff']
            
            #íŒŒì´ì°¨íŠ¸ ìƒì„±
            plt.figure(figsize=(3, 3))
            plt.title(f"{data.columns[i]}ì»¬ëŸ¼ 0ë¹„ìœ¨")
            plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)
            plt.axis('equal')
            plt.show()

    # ê° ì»¬ëŸ¼ë³„ ìƒê´€ë„ ë†’ì€ìˆœìœ¼ë¡œ ë½‘ê¸°
    def show_corr(data,count):
        import numpy as np
        data2 = data.select_dtypes(include=np.number).columns
        filtered_corr = data2.corr()
        for i in range(len(filtered_corr.columns)):
            abs_values = filtered_corr[filtered_corr.columns[i]].abs()

            top_values = abs_values.nlargest(count)
            print(f"{filtered_corr.columns[i]} ì»¬ëŸ¼ì˜ ìƒê´€ê³„ìˆ˜ íƒ‘ 5\n\n",top_values[0:count],"\n")
    
    
        ## ë†ê°€ë³„ë¡œ ë°ì´í„° ë‚˜ëˆ„ê¸° 
    def seperate_col_data(df,colname):
        # df  =out
        # colname ='ì‹œì„¤ì•„ì´ë””'
        uniq_of_col_data = df[colname].unique().tolist()
        print(yellow(f" {colname}ì—ëŠ” {len(uniq_of_col_data)} ì¢…ë¥˜ì˜ ë°ì´í„° ê°€ìˆìŠµë‹ˆë‹¤. "))
        seperated_data = {}
        for i in uniq_of_col_data:
            seperated_data[i] = df[df[colname]==i] 
        data_shapes=[seperated_data[i].shape for i in uniq_of_col_data]
        
        print(yellow(f" ê¸°ì¡´ì˜ data ë¥¼ "))
        for (i,j) in zip(list(seperated_data.keys()),data_shapes):
            print(yellow(f"  {i} : {j}"))
        else:print(yellow(f" ë¡œ ìª¼ê°­ë‹ˆë‹¤"))
        
        # print(yellow(f"{}"))
        # return seperated_data
    ## ë†ì‚¬ê¸°ê°„ ê³„ì‚°
    def calc_duration(df, datetime_col):
        from datetime import datetime
        if datetime_col in df.columns :
            if df[datetime_col].dtype=='O':
                test_dt_start= df[datetime_col].sort_values(ignore_index=True,ascending=True).tolist()[0]
                test_dt_end= df[datetime_col].sort_values(ignore_index=True,ascending=True).tolist()[-1]
                
                # datetime.fromtimestamp(test_dt)
                date_start = datetime.strptime(test_dt_start, '%Y-%m-%d %H:%M').date()
                date_end = datetime.strptime(test_dt_end, '%Y-%m-%d %H:%M').date()
                return (date_end- date_start).days
            elif df[datetime_col].dtype=='int64':
                test_dt_start= df[datetime_col].sort_values(ignore_index=True,ascending=True).tolist()[0]
                test_dt_end= df[datetime_col].sort_values(ignore_index=True,ascending=True).tolist()[-1]
                date_start = datetime.strptime(str(test_dt_start), '%Y%m%d')
                date_end = datetime.strptime(str(test_dt_end), '%Y%m%d')
                return (date_end- date_start).days
    ## ì£¼ì°¨ ê³„ì‚° í•¨ìˆ˜
    def calculate_week(date, base_date, base_week):
            base_date_timestamp = pd.Timestamp(base_date)

            # ë‚ ì§œ ì°¨ì´ ê³„ì‚°
            delta_days = (date - base_date_timestamp).dt.days

            # ê¸°ì¤€ ì£¼ì°¨ì—ì„œ ë‚ ì§œ ì°¨ì´ë¥¼ ì£¼ ë‹¨ìœ„ë¡œ ë³€í™˜
            week = base_week + delta_days // 7
            return week
    
class DataAcquisition():
    def selenium_APIdata_get(endpoint_base,encode_key,pageNum=1,Rows=1):
        from urllib.parse import urlencode,unquote
        decode_key ="w1N+WdpiUt4yMy2JifOenamzNXc6HCceZ596C21rNM+LICP2KiUHN0E0F3Zf4Yu13zM8Myc/ZtIzgFBcywyxXQ=="
        queryString ="?"+urlencode(
            {
                "serviceKey":unquote(f"{encode_key}"),
                "pageNo":1,
                "numOfRows":1,
                "resultType":"json",
                
            }
        )
        query_URL = endpoint_base+queryString
        # !pip install selenium
        # !pip install webdriver-manager
        from selenium import webdriver
        from selenium.webdriver.chrome.service import Service
        from webdriver_manager.chrome import ChromeDriverManager
        from selenium.webdriver.common.by import By
        import json
        from pprint import pprint
        # Chrome browser  ì™€ Chrome Driver Version í™•ì¸í•˜ê¸° 
        chrome_options = webdriver.ChromeOptions()

        hrome_options = webdriver.ChromeOptions()
        chrome_options.add_argument('--headless')  # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ í™œì„±í™”
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
        driver.get(query_URL)
        data =driver.find_element(By.XPATH,'/html/body/pre').text
        data_json = json.loads(data)

        pprint(data_json["response"])
    
    def request_APIData_get():
        ## Author : ì§€í™˜ íŒ
        import requests
        import logging
        import ssl
        import pandas as pd
        from requests.adapters import HTTPAdapter
        from requests.packages.urllib3.util.ssl_ import create_urllib3_context

        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

        # SSL ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        ctx = create_urllib3_context()
        ctx.set_ciphers('DEFAULT@SECLEVEL=1')

        # ì»¤ìŠ¤í…€ ì–´ëŒ‘í„° í´ë˜ìŠ¤ ì •ì˜
        class CustomAdapter(HTTPAdapter):
            def init_poolmanager(self, *args, **kwargs):
                kwargs['ssl_context'] = ctx
                return super(CustomAdapter, self).init_poolmanager(*args, **kwargs)

        # ì„¸ì…˜ ìƒì„± ë° ì–´ëŒ‘í„° ì„¤ì •
        session = requests.Session()
        session.mount('https://', CustomAdapter())

        # API ì—”ë“œí¬ì¸íŠ¸ URL
        url = "https://apis.data.go.kr/B190001/cardFranchisesV3/cardV3"

        # ì¸ì¦í‚¤
        api_key = "1gpaK4ticgtOqnE5t7cIOQtKz7kP4Lu3HbyACKUWni5Ag/yj9cl9uueNXK20lnGIEqPnYSMiSOmR61YL9xS40g=="

        # ìš”ì²­ íŒŒë¼ë¯¸í„°
        params = {
            "serviceKey": api_key,
            "page": "1",
            "perPage": "3000"
        }

        # ìš”ì²­ í—¤ë”
        headers = {
            "accept": "*/*",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
        }

        try:
            # GET ìš”ì²­ ë³´ë‚´ê¸°
            response = session.get(url, params=params, headers=headers, timeout=30)
            
            # ì‘ë‹µ ìƒíƒœ í™•ì¸
            response.raise_for_status()
            
            # JSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„° íŒŒì‹±
            data = response.json()
            
            # ë°ì´í„° ì¶”ì¶œ ë° DataFrame ìƒì„±
            items = data.get('data', [])
            if items:
                df = pd.DataFrame(items)
                logging.info("DataFrame ìƒì„± ì™„ë£Œ")
                logging.info(f"DataFrame shape: {df.shape}")
                logging.info("\nDataFrame ì²« 5í–‰:")
                logging.info(df.head().to_string())
            else:
                logging.warning("ì¶”ì¶œëœ ë°ì´í„° í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                logging.info("ì‘ë‹µ ë°ì´í„°:")
                logging.info(json.dumps(data, indent=2, ensure_ascii=False))

        except requests.exceptions.RequestException as e:
            logging.error(f"ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            if hasattr(e, 'response') and e.response is not None:
                logging.error(f"ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {e.response.status_code}")
                logging.error(f"ì‘ë‹µ ë‚´ìš©: {e.response.text}")
            else:
                logging.error("ì‘ë‹µ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except ValueError as e:
            logging.error(f"JSON ë””ì½”ë”© ì˜¤ë¥˜: {e}")
            logging.error(f"ì‘ë‹µ ë‚´ìš©: {response.text}")
        except Exception as e:
            logging.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

class Visualization():
    
    def plot_boxplots(datasets, titles, figsize=(10, 20)):
        
        import seaborn as sns
        import matplotlib.pyplot as plt
        import platform,os
        from matplotlib import font_manager, rc
        

        # ì‹œê°í™” ì„¤ì •
        plt.style.use("seaborn-v0_8")
        plt.rcParams['axes.unicode_minus'] = False
        
        # ì‹œìŠ¤í…œì— ë”°ë¥¸ í°íŠ¸ ì„¤ì •
        if platform.system() == 'Darwin': 
            rc('font', family='AppleGothic')
        elif platform.system() == 'Windows': 
            path = 'c:/Windows/Fonts/malgun.ttf' 
            font_name = font_manager.FontProperties(fname=path).get_name()
            rc('font', family=font_name)
        else:
            print("Unknown System")

        # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        fig, axes = plt.subplots(len(datasets), 1, figsize=figsize)  # ë°ì´í„°ì…‹ ê°œìˆ˜ì— ë”°ë¼ ì„œë¸Œí”Œë¡¯ ìƒì„±

        for i, data in enumerate(datasets):
            sns.boxplot(data=data, ax=axes[i])
            axes[i].set_title(titles[i])

        # ê·¸ë˜í”„ ê°„ê²© ì¡°ì ˆ
        plt.tight_layout()

        # ê·¸ë˜í”„ ì¶œë ¥
        plt.show()
        # í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì‹œ
        # datasets = [out, B, C, D, E]
        # titles = ['ì‚¬ì „í…ŒìŠ¤íŠ¸ ìƒìœ¡ë°ì´í„°', 'í™˜ê²½ ë°ì´í„° B', 'í™˜ê²½ ë°ì´í„° C', 'í™˜ê²½ ë°ì´í„° D', 'í™˜ê²½ ë°ì´í„° E']
        # plot_boxplots(datasets, titles)

class ModelTest():
    # ì˜ˆì‹œ ë°ì´í„° (training_tableê³¼ target_tableì´ ì´ë¯¸ ì¡´ì¬í•œë‹¤ê³  ê°€ì •)
    # training_table = pd.DataFrame(...)
    # target_table = pd.DataFrame(...)

    # ë°ì´í„° ë¶„í• 
    def real_pred_compare(predictions,test_target,test_input):
        print(yellow("ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸[[ì‹¤ì œ ì˜ˆì¸¡ê°’ í™•ì¸]]ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸"))
        for idx,(pred_result,real,test_in) in enumerate(zip(predictions,test_target.values,test_input.values)):
            if idx < 4:
                str_real = "\t"
                str_pred = "\t"
                str_input = "\t"
                for i in list(real):
                    str_real = "\t".join("{:>8d}".format(int(val)) for val in real)
                for j in list(map(int,(pred_result))):
                    str_pred = "\t".join("{:>8d}".format(int(val)) for val in pred_result)
                for k in list(test_in):
                    str_input += str(k) + "\t"

                
                print(f"***** {idx} ë²ˆì§¸ test ê²°ê³¼ ***** ")
                print("ì¸í’‹ ì •ë³´"+"---"*200)
                print(f"ì¸í’‹ì¹¼ëŸ¼","\t".join((list(test_input.columns))),sep = "\t\t")
                print(f"***ì¸í’‹\t  {str_input}", sep='\t')
                print("ì•„ì›ƒí’‹ ì •ë³´"+"---"*200)
                print(f"  ","\t".join((list(test_target.columns))),sep = "\t\t")
                formatted_columns = "\t".join("{:>8s}".format(col) for col in list(test_target.columns))
                print(f"    \t{formatted_columns}")
                print(f"ì‹¤ì œ\t  {str_real}", sep='\t')
                print(f"ì˜ˆì¸¡\t  {str_pred}", sep='\t')

    def linear_regressor_prdict(train_input, train_target, test_input, test_target):
        from statistics import LinearRegression
        import numpy as np
        from sklearn.multioutput import MultiOutputRegressor
        from sklearn.linear_model import LinearRegression
        from sklearn.metrics import mean_squared_error
        from sklearn.metrics import mean_squared_error, r2_score
        from sklearn.model_selection import cross_val_score
        import joblib

        ## Linear Regression model ë¹„êµ
        lin_regressor = LinearRegression()
        multi_output_regressor_lin = MultiOutputRegressor(lin_regressor)
        multi_output_regressor_lin.fit(train_input, train_target)
        y_pred_lin = multi_output_regressor_lin.predict(test_input)
        mse = mean_squared_error(test_target, y_pred_lin)
        rmse = np.sqrt(mse)
        r2 = r2_score(test_target, y_pred_lin) 
        
        #### êµì°¨ê²€ì¦ 
        scores_cv = cross_val_score(multi_output_regressor_lin,train_input,train_target,scoring='neg_mean_squared_error',cv=10)
        rmse_cv = np.sqrt(-scores_cv)
        print(f"Linear regression model RMSE: {rmse:.2f}")
        print(f"Linear regression model R2 score: {r2:.2f}")
        print("\t ",f"LR cv score : {rmse_cv}")
        print("\t ",f"LR cv RMSE  average : {rmse_cv.mean():.2f}")
                # ëª¨ë¸ ì €ì¥
        joblib.dump(multi_output_regressor_lin, "Linear_model")
        print(f'ëª¨ë¸ì´ {"Linear_model"} ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨')
        predictions = multi_output_regressor_lin.predict(test_input)
        ModelTest.real_pred_compare(predictions,test_target,test_input)

    def knn_regressor_predict(train_input, train_target, test_input, test_target, multi_out=True):
        ### Description: multiioutput ì¼ë•Œì™€ single output ì¼ ë•Œ êµ¬ë¶„í•´ì„œ í•™ìŠµí•˜ë„ë¡ í•¨. 
        ### Date : 2024.08.29 
        
        import numpy as np
        from sklearn.multioutput import MultiOutputRegressor
        from sklearn.neighbors import KNeighborsRegressor
        from sklearn.metrics import mean_squared_error
        from xgboost import XGBRegressor
        from sklearn.metrics import mean_squared_error, r2_score
        from sklearn.model_selection import cross_val_score
        import joblib

        ## KNN regression model
        knn_regressor = KNeighborsRegressor(n_neighbors=3)

        if multi_out:
            ## Multi Output Setting
            multi_output_regressor_knn = MultiOutputRegressor(knn_regressor)
            multi_output_regressor_knn.fit(train_input, train_target)
            score = multi_output_regressor_knn.score(test_input, test_target)
            y_pred_knn = multi_output_regressor_knn.predict(test_input)
            mse = mean_squared_error(test_target, y_pred_knn)
            rmse = np.sqrt(mse)
            # R2 ìŠ¤ì½”ì–´ ê³„ì‚°
            r2 = r2_score(test_target, y_pred_knn)
            print(yellow(f'KNN(k=3) regression model score: {score}'))
            print(yellow(f'KNN(k=3) regression model RMSE: {rmse:.2f}'))
            print(yellow(f'KNN regression R2 score: {r2:.2f}'))
            #### êµì°¨ê²€ì¦ 
            scores_cv = cross_val_score(multi_output_regressor_knn, train_input, train_target, scoring='neg_mean_squared_error', cv=10)
            rmse_cv = np.sqrt(-scores_cv)
            print(rainbow_orange(f" â—‰ KNN Cross Validation score : {rmse_cv}"))
            print(rainbow_orange(f" â—‰ KNN Cross Validation RMSE average : {rmse_cv.mean():.2f}"))
            # ëª¨ë¸ ì €ì¥
            joblib.dump(multi_output_regressor_knn, "KNN_model")
            print(f'ëª¨ë¸ì´ {"KNN_model"} ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨')
            predictions = multi_output_regressor_knn.predict(test_input)

        else:  # multi_outì´ Falseì¼ ê²½ìš°
            knn_regressor.fit(train_input, train_target)  # KNeighborsRegressorë¥¼ í•™ìŠµ
            score = knn_regressor.score(test_input, test_target)
            y_pred_knn = knn_regressor.predict(test_input)
            mse = mean_squared_error(test_target, y_pred_knn)
            rmse = np.sqrt(mse)
            # R2 ìŠ¤ì½”ì–´ ê³„ì‚°
            r2 = r2_score(test_target, y_pred_knn)
            print(yellow(f' â—‰ KNN(k=3) regression model score: {score:.2f}'))
            print(yellow(f' â—‰ KNN(k=3) regression model RMSE: {rmse:.2f}'))
            print(yellow(f' â—‰ KNN regression R2 score: {r2:.2f}'))
            #### êµì°¨ê²€ì¦ 
            scores_cv = cross_val_score(knn_regressor, train_input, train_target, scoring='neg_mean_squared_error', cv=10)
            rmse_cv = np.sqrt(-scores_cv)
            print(rainbow_orange(f" â—‰ KNN Cross Validation RMSE : "))
            for order,i in enumerate(rmse_cv):
                if order ==0:
                    print("    : ",end="")
                print(f" {i:.3f} ",end=", ")
            else: print()
            print(rainbow_orange(f" â—‰ KNN Cross Validation RMSE average : {rmse_cv.mean():.2f}"))
            # ëª¨ë¸ ì €ì¥
            joblib.dump(knn_regressor, "KNN_model")
            print(f'ëª¨ë¸ì´ {"KNN_model"} ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨')
            predictions = knn_regressor.predict(test_input)

    def xgboost_regressor_predict(train_input, train_target, test_input, test_target, multi_out=True):
        """
        XGBoost íšŒê·€ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì˜ˆì¸¡í•©ë‹ˆë‹¤. 

        Args:
            train_input (pd.DataFrame): í•™ìŠµ ë°ì´í„°ì˜ ì…ë ¥ íŠ¹ì„±
            train_target (pd.Series): í•™ìŠµ ë°ì´í„°ì˜ ëª©í‘œ ê°’
            test_input (pd.DataFrame): í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì…ë ¥ íŠ¹ì„±
            test_target (pd.Series): í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ëª©í‘œ ê°’
            multi_out (bool, optional): ì—¬ëŸ¬ ì¶œë ¥ ê°’ì„ ì˜ˆì¸¡í• ì§€ ì—¬ë¶€. ê¸°ë³¸ê°’ì€ Trueì…ë‹ˆë‹¤.

        Returns:
            None: ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê³  ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤.
        """

        import numpy as np
        from sklearn.multioutput import MultiOutputRegressor
        from sklearn.metrics import mean_squared_error
        from xgboost import XGBRegressor
        from sklearn.metrics import mean_squared_error, r2_score
        from sklearn.model_selection import cross_val_score
        import joblib

        # xg_reg = XGBRegressor(enable_categorical=True)
        xg_reg = XGBRegressor(enable_categorical=True, feature_names=train_input.columns[:-1]) # feature_names ì„¤ì •
        # ë°ì´í„° íƒ€ì… ë³€í™˜ (í•„ìš”ì— ë”°ë¼)
        for col in train_input.columns:
            if col == 'Smiles':  # SMILES ì»¬ëŸ¼ì€ ì œì™¸
                continue
            train_input[col] = train_input[col].astype(int)  # ëª¨ë“  ì—´ì„ int íƒ€ì…ìœ¼ë¡œ ë³€í™˜ (í•„ìš”ì— ë”°ë¼ ë‹¤ë¥¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜)
            test_input[col] = test_input[col].astype(int)  # test_inputë„ ë§ˆì°¬ê°€ì§€ë¡œ ë³€í™˜

        if multi_out:
            # ì—¬ëŸ¬ ì¶œë ¥ ê°’ ì˜ˆì¸¡ ì„¤ì •
            multi_output_regressor_xg = MultiOutputRegressor(xg_reg)
            multi_output_regressor_xg.fit(train_input, train_target)

            score = multi_output_regressor_xg.score(test_input, test_target)
            y_pred_xg = multi_output_regressor_xg.predict(test_input)
            mse = mean_squared_error(test_target, y_pred_xg)
            rmse = np.sqrt(mse)
            # R2 ìŠ¤ì½”ì–´ ê³„ì‚°
            r2 = r2_score(test_target, y_pred_xg)   
            print(yellow(f' â—‰ XGB regression model score: {score:.2f}'))
            print(yellow(f' â—‰ XGBoost(3) regression model RMSE: {rmse:.2f}'))
            print(yellow(f' â—‰ XGBoost regression model R2 score: {r2:.2f}'))
            ### êµì°¨ê²€ì¦
            scores_cv = cross_val_score(multi_output_regressor_xg, train_input, train_target, scoring='neg_mean_squared_error', cv=10)
            rmse_cv = np.sqrt(-scores_cv)
            # ëª¨ë¸ ì €ì¥
            joblib.dump(multi_output_regressor_xg, "XG_model")
            print(f'ëª¨ë¸ì´ {"XG_model"} ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨')
            print(rainbow_orange(f" â—‰ XGB Cross Validation RMSE : "))
            for order, i in enumerate(rmse_cv):
                if order == 0:
                    print("    : ", end="")
                print(f" {i:.3f} ", end=", ")
            else:
                print()
            print(rainbow_orange(f" â—‰ XGB Cross Validation RMSE average : {rmse_cv.mean():.2f}"))
            predictions = multi_output_regressor_xg.predict(test_input)

        else:
            # ë‹¨ì¼ ì¶œë ¥ ê°’ ì˜ˆì¸¡
            xg_reg.fit(train_input, train_target)

            score = xg_reg.score(test_input, test_target)
            y_pred_xg = xg_reg.predict(test_input)
            mse = mean_squared_error(test_target, y_pred_xg)
            rmse = np.sqrt(mse)
            # R2 ìŠ¤ì½”ì–´ ê³„ì‚°
            r2 = r2_score(test_target, y_pred_xg)
            print(yellow(f' â—‰ XGB regression model score: {score:.2f}'))
            print(yellow(f' â—‰ XGBoost(3) regression model RMSE: {rmse:.2f}'))
            print(yellow(f' â—‰ XGBoost regression model R2 score: {r2:.2f}'))
            ### êµì°¨ê²€ì¦
            scores_cv = cross_val_score(xg_reg, train_input, train_target, scoring='neg_mean_squared_error', cv=10)
            rmse_cv = np.sqrt(-scores_cv)
            # ëª¨ë¸ ì €ì¥
            joblib.dump(xg_reg, "XG_model")
            print(f'ëª¨ë¸ì´ {"XG_model"} ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨')
            print(rainbow_orange(f" â—‰ XGB Cross Validation RMSE : "))
            for order, i in enumerate(rmse_cv):
                if order == 0:
                    print("    : ", end="")
                print(f" {i:.3f} ", end=", ")
            else:
                print()
            print(rainbow_orange(f" â—‰ XGB Cross Validation RMSE average : {rmse_cv.mean():.2f}"))
            predictions = xg_reg.predict(test_input)

        # ModelTest.real_pred_compare(predictions, test_target, test_input)

    def randomforest_regressor_predict(train_input, train_target, test_input, test_target):
        import numpy as np
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.multioutput import MultiOutputRegressor
        from sklearn.metrics import mean_squared_error
        from xgboost import XGBRegressor
        from sklearn.metrics import mean_squared_error, r2_score
        from sklearn.model_selection import cross_val_score
        import joblib
        import os

        rf_reg = RandomForestRegressor(n_estimators=1, random_state=42)
        multi_output_regressor_rf = MultiOutputRegressor(rf_reg)
        multi_output_regressor_rf.fit(train_input, train_target)

        y_pred_rf = multi_output_regressor_rf.predict(test_input)
        mse = mean_squared_error(test_target, y_pred_rf)
        rmse = np.sqrt(mse)
        r2 = r2_score(test_target, y_pred_rf)

        print(yellow(f'RandomForest regression model RMSE: {rmse:.2f}'))
        print(f'RandomForest regression model R2 score: {r2:.2f}')

        # êµì°¨ ê²€ì¦
        scores_cv = cross_val_score(multi_output_regressor_rf, train_input, train_target, 
                                    scoring='neg_mean_squared_error', cv=10)
        rmse_cv = np.sqrt(-scores_cv)
        print("\t ", red(f"RF cv RMSE scores: {rmse_cv}"))
        print("\t ", green(f"RF cv RMSE average: {rmse_cv.mean():.2f}"))

        # R2 êµì°¨ ê²€ì¦
        r2_scores_cv = cross_val_score(multi_output_regressor_rf, train_input, train_target, 
                                    scoring='r2', cv=10)
        print("\t ", red(f"RF cv R2 scores: {r2_scores_cv}"))
        print("\t ", green(f"RF cv R2 average: {r2_scores_cv.mean():.2f}"))

        # ëª¨ë¸ ì €ì¥
        joblib.dump(multi_output_regressor_rf, "RF_model")
        print(f'ëª¨ë¸ì´ {"RF_model"} ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨')

        predictions = multi_output_regressor_rf.predict(test_input)
        ModelTest.real_pred_compare(predictions, test_target, test_input)


    
if __name__ == "__main__":
    import pandas as pd ,sys
    input_data = pd.read_csv('/Users/forrestdpark/Desktop/PDG/Python_/BerryMLcompetetion/BerryMachineLearning/ì˜ˆì„ ì—°ìŠµ_2023_tomato/Data/2023_smartFarm_AI_hackathon_dataset.csv')
    while True : 
        yellow("í”„ë¡œê·¸ë¨ ì‹œì‘")
        # DataPreprocessing.plotSetting()
        DataPreprocessing.dataInfo(input_data)
        print(green("ë‹¤ì‹œ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆë‹ˆê¹Œ?(yes =1, no=0): "))
        restart_query = int(sys.stdin.readline())
        if restart_query == 0:
            break     
    
